## 第 3 章。使用税务数据和 Python 创建面向应用程序的分析

在本章中，我们将介绍：

*   准备分析最高收入
*   导入和探索世界上最高收入的数据集
*   分析和可视化美国的最高收入数据
*   进一步分析美国的最高收入群体
*   用 Jinja2 进行报告
*   在 R 中重复分析

## 简介

* * *

在本书中，我们采用一种实用的方法来使用 R 和 Python 进行数据分析。 我们可以相对轻松地回答有关特定数据集的问题，生成模型并导出可视化效果。 因此，R 是快速原型设计和分析的绝佳选择，因为 R 是专为统计数据分析而设计的领域特定语言，并且表现出色。

在本书中，我们将介绍另一种更适合生产环境和应用程序的分析方法。 假设，获取，清理和整理，分析，建模，可视化和应用程序的数据科学管道无论如何都不是一个干净，线性的过程。 此外，当分析要以自动化的方式进行大规模重现时，许多新的考虑因素和要求也应运而生。 因此，许多数据应用程序需要更广泛的工具箱。 该工具包仍应提供快速原型制作，在所有系统上普遍可用，并为一系列计算操作（包括网络操作，数据操作和科学操作）提供全面支持。 鉴于这些要求，Python 显然是面向应用程序分析的首选工具。

Python 是一种解释语言（有时也称为脚本语言），与 R 十分相似。它不需要特殊的 IDE 或软件编译工具，因此使用 R 和开发原型的速度与 R 一样快。 与 R 一样，它也使用 C 共享库来提高计算性能。 此外，Python 是 Linux，Unix 和 macOS X 机器上的默认系统工具，并且也可用于 Windows。 Python 装有电池，这意味着标准库广泛包含了从多处理到压缩工具集的许多模块。 Python 是一个灵活的计算中心，可以解决任何领域问题。 如果您发现需要标准库之外的库，Python 还附带了一个软件包管理器（如 R），该软件包管理器允许下载和安装其他代码库。

Python 的计算灵活性意味着某些分析任务比 R 中的对应任务需要更多的代码行。但是，Python 确实具有允许其执行相同统计计算的工具。 这就引出了一个明显的问题：*我们何时在 Python 上使用 R，反之亦然？* 本章试图通过采用面向应用的方法进行统计分析来回答这个问题。

### 面向应用程序的方法简介

数据应用程序和数据产品正日益成为我们日常生活的一部分。 这些产品比简单的数据驱动的 Web 应用程序具有更广泛的应用范围，简单的数据驱动 Web 应用程序包括由数据库支持的各种前端 Web 和移动应用程序，并包括用于处理事务的中间件。 根据这个定义，简单的博客与大型电子商务站点没有本质上的区别。 取而代之的是，数据产品和设备从数据本身获取价值，并创建更多数据。

这些类型的应用程序可用于丰富传统应用程序，例如博客的语义标记或电子商务站点的推荐引擎。 另一方面，它们本身就可以成为独立的数据产品，包括从量化的自助设备到自动驾驶汽车的所有产品。

与更传统的数据挖掘或静态数据集的统计评估不同，在实时或流式上下文中对数据的处理和分析似乎是面向应用的分析的定义特征。 为了处理此类数据，需要大量的程序敏捷性或动态方法，而灵活性恰恰是 Python 在数据科学领域的亮点。

考虑报告任务的特定示例。 拍摄数据窗口快照并使用图表和可视化图表从收集的分析中手动编译报告是了解更改数据并了解较大模式的好习惯。 当该报告需要每天在较小的数据量上运行时，调度程序仅可以每天将报告转储到文件中。 但是，当报告任务变成每小时一次或按需执行时，这意味着可视化应用程序已变为静态 Web 应用程序，并且可能需要在中心位置。 随着此任务和数据大小的增长，在报表上添加约束或查询变得很重要。 这是数据应用程序的典型生命周期，Python 开发非常适合处理这些不断变化的需求。

我们将描述，建模和可视化包含世界上最高收入的数据集，并讨论 Python 中的统计工具包。 但是，在阅读本章时，我们还将包括有关如何在面向应用程序的上下文中构建我们正在使用的分析和方法的说明。

## 为分析最高收入做准备

* * *

对于以下食谱，您将需要在计算机上安装 Python，并且需要世界上收入最高的数据集。 此食谱将帮助确保您已设置完成此分析项目所需的一切。

### 准备

要逐步阅读此食谱，您将需要一台可访问互联网的计算机。 确保已下载并安装 Python 和必要的 Python 库以完成此项目。

### 注意

请参阅第 1 章，“准备数据科学环境”，以使用`virtualenv`设置 Python 开发环境并安装`matplotlib`和`NumPy`所需的库。

### 怎么做...

以下步骤将指导您下载世界上收入最高的数据集，并安装必要的 Python 库以完成此项目：

### 注意

可以从[这个页面](http://topincomes.g-mond.parisschoolofeconomics.eu/)下载世界最高收入的原始数据集。 但是，该站点已进行了多次更新，从而更改了数据的输出格式（从`.csv`更改为`.xlsx`）。 该配方采用`.csv`文件格式。 本章的存储库包含输入数据文件的正确格式版本。

1.  将全球收入最高的数据集保存到计算机上可以找到它的位置。
2.  打开终端窗口并启动 Python 解释器。
3.  检查并确保安装了以下三个库`NumPy`，`matplotlib`和`Jinja2`； 尝试导入每个：

```
In [2]: import numpy as np 
   ...: import jinja2 
   ...: import matplotlib as plt 
```

前面的每个库都应从 Python 导入而无需添加注释或注释。 如果他们这样做，那您就很好了。 如果不是，请参考第 1 章和“准备数据科学环境”来设置系统。

### 工作原理...

NumPy 是 Python 的基础科学计算库； 因此，它对于任何数据科学工具包都是必不可少的，我们将在整个 Python 章节的许多地方使用它。 但是，由于 NumPy 是必须为您的系统编译的外部库，因此我们将与 NumPy 方法一起讨论其他本机 Python 方法。

## 导入和探索世界上最高收入的数据集

* * *

在下载并安装了先前配方中的所有内容之后，您可以使用 Python 读取数据集，然后开始进行一些初步分析以了解您所拥有的数据的样子。

我们将在本章中探讨的数据集由 *Alvaredo*，*Facundo*，*Anthony B. Atkinson*，*Thomas Piketty* 和 *Emmanuel Saez*，[世界最高收入数据库](http://topincomes.g-mond.parisschoolofeconomics.eu/)，*2013 年 10 月 12 日*。 它包含从税收记录中收集到的有关过去 100 年来每个国家/地区最高收入的全球信息。

### 准备

如果您已完成先前的食谱*，为分析最高收入*做准备，则应具备继续进行所需的一切。

### 怎么做...

让我们使用以下步骤序列来导入数据，并开始在 Python 中对该数据集进行探索：

1.  使用以下代码段，我们将在内存中创建一个 Python 列表，其中包含每一行的字典，其中的键是列名（CSV 的第一行包含标题信息），而值是该特定行的值：

```
In [3]: import csv 
 ...: data_file = "../data/income_dist.csv" 
 ...: with open(data_file, 'r') as csvfile: 
 ...: reader = csv.DictReader(csvfile) 
 ...: data = list(reader)
```

### 注意

请注意，根据放置位置，输入文件`income_dist.csv`可能位于系统的其他目录中。

2.  我们使用`len`快速检查以显示记录数：

```
In [4]: len(data) 
 ...: 
Out[4]: 2180
```

3.  当使用带标题的 CSV 数据时，我们会检查 CSV 阅读器本身的字段名称，并获取变量数：

```
In [5]: len(reader.fieldnames) 
 ...: 
Out[5]: 354
```

4.  尽管这些数据不是太大，但是让我们在访问数据时开始使用最佳实践。 我们不是使用所有生成器将数据保存在内存中，而是使用生成器来一次访问一行数据。

生成器是 Python 表达式，可让您创建充当可迭代函数的函数。 它们不返回所有数据，而是在内存有效的迭代上下文中一次生成一个数据。 随着我们的数据集变得越来越大，使用生成器按需执行过滤并在您读取数据时清理数据很有用：

```
In [6]: def dataset(path): 
 ...: with open(path, 'r') as csvfile: 
 ...: reader = csv.DictReader(csvfile)
 ...: for row in reader: 
 ...: yield row
```

另外，请注意 with `open(path, 'r') as csvfile`语句。 该语句可确保在退出 with 块时，即使（或特别是）存在异常时，也将关闭 CSV 文件。 带块的 Python 替换了 try，except 和 finally 语句，并且语法简短，而语义上更正确的编程构造。

5.  使用我们的新功能，我们可以确定数据集中涉及哪些国家：

```
In [7]: print(set([row["Country"] for row in dataset(data_file)])) 

 ...: set(['Canada', 'Italy', 'France', 'Netherlands', 'Ireland',...])
```

6.  我们还可以检查此数据集涵盖的年份范围，如下所示：

```
In [8]: print(min(set([int(row["Year"]) for row in dataset(data_file)]))) 
 ...: 
1875 

In [9]: print(max(set([int(row["Year"]) for row in dataset(data_file)]))) 
 ...: 
2010
```

7.  在以上两个示例中，我们都使用 Python 列表推导生成了一个集合。 理解是一种简洁的语句，它生成可迭代的语句，与早期的内存安全生成器非常相似。 指定了一个或多个输出变量以及 for 关键字，并且可迭代地表示该变量以及一个可选的 if 条件。 在 Python 3.6 中，集合和字典的理解也存在。 先前的国家/地区设置也可以表示如下：

```
In [10]: {row["Country"] for row in dataset(data_file)} 
 ...: set(['Canada', 'Italy', 'France', 'Netherlands', 'Ireland',...]) 
Out[10]: {'Netherlands', Ellipsis, 'Ireland', 'Canada', 'Italy', 'France'}
```

8.  最后，让我们只过滤美国的数据，以便我们可以对其进行独家分析：

```
In [11]: filter(lambda row: row["Country"] == "United States", 
 ...: dataset(data_file)) 

Out[11]: <filter at 0xb1aeac8>
```

Python 筛选器函数根据使第一个参数指定的函数为 true 的序列或可迭代（第二个参数）的所有值创建一个列表。 在这种情况下，我们使用匿名函数（Lambda 函数）来检查指定行的“国家/地区”列中的值是否等于“美国”。

9.  通过对数据集的最初发现和探索，我们现在可以使用`matplotlib`来查看一些数据，它是可用于 Python 的主要科学绘图软件包之一，与 MATLAB 的绘图功能非常相似：

```
In [12]: import csv 
 ...: import numpy as np 
 ...: import matplotlib.pyplot as plt 

In [13]: def dataset(path, filter_field=None, filter_value=None): 
 ...: with open(path, 'r') as csvfile: 
 ...: reader = csv.DictReader(csvfile)
 ...: if filter_field: 
 ...: for row in filter(lambda row: 
 ...: row[filter_field]==filter_value, reader): 
 ...: yield row 
 ...: else: 
 ...: for row in reader: 
 ...: yield row 

In [14]: def main(path): 
 ...: data = [(row["Year"], float(row["Average income per tax unit"])) 
 ...: for row in dataset(path, "Country", "United States")] 
 ...: width = 0.35 
 ...: ind = np.arange(len(data)) 
 ...: fig = plt.figure() 
 ...: ax = plt.subplot(111) 
 ...: ax.bar(ind, list(d[1] for d in data))
 ...: ax.set_xticks(np.arange(0, len(data), 4)) 
 ...: ax.set_xticklabels(list(d[0] for d in data)[0::4],rotation=45) 
 ...: ax.set_ylabel("Income in USD") 
 ...: plt.title("U.S. Average Income 1913-2008") 
 ...: plt.show() 

In [15]: if __name__ == "__main__": 
 ...: main("income_dist.csv")
```

上面的代码片段将为我们提供以下输出：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_03_001.png)

在 R 的许多章节中，使用 Python 进行数据探索的上述示例似乎都很熟悉。 加载数据集，过滤和计算范围需要几行代码和特定的类型转换，但是我们以内存安全的方式快速创建了分析。

10.  当我们继续创建图表时，我们开始更多地使用`NumPy`和`matplotlib`。 NumPy 的用法与 R 非常相似，可以将数据从 CSV 文件加载到内存中的数组，并动态确定每一列的类型。 为此，可以使用以下两个模块功能：

*   `genfromtext`：此函数使用两个主循环从存储在文本文件中的表格数据创建数组。 第一个将文件的每一行转换为字符串序列，第二个将每个字符串转换为适当的数据类型。 这有点慢，并且不如内存效率高，但是结果是在内存中存储了一个方便的数据表。 此功能还可以处理丢失的数据，而其他更快更简单的功能则不能。
*   `recfromcsv`：此功能是基于`genfromtext`的帮助程序功能，其默认参数设置为提供对 CSV 文件的访问。

看一下以下代码片段：

```
In [16]: import numpy as np 

 ...: dataset = np.recfromcsv(data_file, skip_header=1) 

 ...: dataset 

array([[             nan,   1.93200000e+03,              nan, ..., 
 nan,   1.65900000e+00,   2.51700000e+00], 
 [             nan,   1.93300000e+03,              nan, ..., 
 nan,   1.67400000e+00,   2.48400000e+00], 
 [             nan,   1.93400000e+03,              nan, ..., 
 nan,   1.65200000e+00,   2.53400000e+00], 
 ..., 
 [             nan,   2.00600000e+03,   4.52600000e+01, ..., 
 1.11936337e+07,   1.54600000e+00,   2.83000000e+00], 
 [             nan,   2.00700000e+03,   4.55100000e+01, ..., 
 1.19172976e+07,   1.53000000e+00,   2.88500000e+00], 
 [             nan,   2.00800000e+03,   4.56000000e+01, ..., 
 9.14119000e+06,   1.55500000e+00,   2.80300000e+00]])
```

该函数的第一个参数应该是数据源。 它应该是指向本地或远程文件的字符串，或者是具有 read 方法的类似文件的对象。 URL 将在加载之前下载到当前工作目录。 此外，输入可以是文本或压缩文件。 该功能可以识别`gzip`和`bzip2`。 这些文件需要具有`.gz`或`.bz2`扩展名才能可读。 `genfromtext`的值得注意的可选参数包括定界符，默认情况下，`recfromcsv;` `skip_header`和`skip_footer`中的定界符`, (comma)`分别需要从顶部或底部跳过的可选行数； 和`dtype`，指定单元的数据类型。 默认情况下，`dtype`为“无”，并且 NumPy 将尝试检测正确的格式。

11.  现在，我们可以大致了解数据表的范围：

```
In [17]: dataset.size 

 ...: 
Out[17]: 2179 

In [18]: (len(dataset)+1)*len(dataset.T[1]) # works on 3.6
 ...: 
Out[18]: 771720 
In [19]: dataset.shape 
 ...: 
Out[19]: (2179,)
```

### 注意

根据您的 NumPy 版本，您可能会看到略有不同的输出。 dataset.size 语句可能会报告返回的数据行数（2179），并且形状可能会输出为（2179，）。

`ndarray`的 size 属性返回矩阵中的元素数。 shape 属性返回数组中尺寸的元组。 CSV 自然是二维的，因此`(m, n)`元组分别指示行数和列数。

但是，使用此方法有一些陷阱。 首先，请注意，我们必须跳过标题行； `genfromtxt`确实通过将关键字参数名称设置为 True 来允许命名列（在这种情况下，您将不会设置`skip_headers=1`）。 不幸的是，在这个特定的数据集中，列名可能包含逗号。 CSV 阅读器可以正确处理此问题，因为包含逗号的字符串被引号引起来，但是`genfromtxt`通常不是 CSV 阅读器。 要解决此问题，要么必须修复标题，要么需要添加其他一些名称。 其次，`Country`列已还原为`NaN`，并且`Year`列已转换为浮点整数，这是不理想的。

12.  手动修复数据集是必要的，而且这种情况并不罕见。 因为我们知道有 354 列，并且前两列是`Country`和`Year`，所以我们可以预先计算我们的列名和数据类型：

```
In [20]: names = ["country", "year"]

 ...: names.extend(["col%i" % (idx+1) for idx in range(352)]) 
 ...: dtype = "S64,i4," + ",".join(["f18" for idx in range(352)]) 
 ...: 
In [21]: dataset = np.genfromcsv(data_file, dtype=np.dtype, names=names, 
 ...: delimiter=",", skip_header=1, autostrip=2) 
 ...: 
```

我们分别将前两列分别命名为 country 和 year，并将它们的数据类型指定为`S64`或`string-64`，然后将 year 列指定为`i4`或`integer-4`。 对于其余的列，我们为它们分配名称`coln`，其中 n 是 1 到 352 之间的整数，数据类型为`f18`或`float-18`。 这些字符长度使我们能够捕获尽可能多的数据，包括指数浮点表示形式。

不幸的是，当我们浏览数据时，我们可以看到很多表示**而不是数字**的`nan`值，浮点运算中的固定装置用于表示非数字或等价于无穷大的值 。 在管道的数据整理和清理阶段，数据丢失是一个非常普遍的问题。 似乎数据集包含许多丢失或无效的条目，这对于历史数据而言是有意义的，而对于给定的列，可能没有有效收集数据的国家/地区也是如此。

13.  为了清除数据，我们使用 NumPy 掩码数组，它实际上是标准 NumPy 数组和掩码的组合，一组布尔值指示是否应在该位置使用数据进行计算。 可以按照以下步骤进行操作：

```
import numpy.ma as ma 
ma.masked_invalid(dataset['col1']) 
masked_array(data = [-- -- -- ..., 45.2599983215332
 45.5099983215332 45.599998474121094], 
mask = [ True  True  True ..., False False False],fill_value = 
 1e+20)
```

### 工作原理...

我们的数据集功能已经过修改，可以根据需要对单个字段和值进行过滤。 如果未指定过滤器，它将生成整个 CSV。 主要的兴趣在于主要功能中发生的事情。 在这里，我们使用 matplotlib 生成了美国每年平均收入的条形图。 让我们来看一下代码。

我们在列表理解中以（`year`，`avg_income`）元组的形式收集数据，该列表利用我们的特殊数据集方法来仅过滤美国的数据。

### 注意

我们必须将每个税收单位的平均收入强制转换为浮点数才能进行计算。 在这种情况下，我们将年份保留为字符串，因为它只是充当标签。 但是，为了执行`datetime`计算，我们可能想使用`datetime.strptime (row['Year'], '%Y').date()`将年份转换为日期。

完成数据收集，过滤和转换后，我们将设置图表。 宽度是条的最大宽度。 `ind`迭代（`ndarray`）是指每个条的`x`轴位置； 在这种情况下，我们需要为集合中的每个数据点分配一个位置。 NumPy `np.arange`函数类似于内置的`xrange`函数； 它会在给定的时间间隔内返回均等值的可迭代（`ndarray`）。 在这种情况下，我们提供一个终止值，该终止值是列表的长度，并使用`0`的默认起始值​​和`1`的步长，但也可以指定这些值。 `arange`的使用允许浮点参数，并且通常比简单地实例化整个值数组要快得多。

`figure`和`subplot`模块功能利用`matplotlab.pyplot`模块分别创建基础图形和轴。 `figure`函数创建一个新图形，或返回对先前创建图形的引用。 `subplot`函数返回由网格定义定位的子图轴，并带有以下参数：行数，列数和图号。 当所有三个自变量都小于 10 时，此功能很方便。只需提供一个三位数的数值（例如`plot.subplot (111)`），即可在子图 1 中创建 *1 x 1* 轴。

然后，我们使用子图根据数据创建条形图。 请注意，另一种理解的使用将来自我们数据集的收入值以及我们使用`np.arange`创建的索引进行传递。 但是，在设置`x`轴标签时，我们注意到，如果将所有年份都添加为单独的标签，则`x`轴是不可读的。 取而代之的是，我们从第一年开始每 4 年添加一次滴答声。 在这种情况下，您可以看到我们在`np.arange`中使用`4`的步长来设置刻度，并且类似地，在标签中，我们使用 Python 列表上的 slice 来遍历每四个标签。 例如，对于给定的列表，我们将使用：

```
mylist[s:e:t]
```

列表的分片开始于`s`，结束于`e`，步长为`t`。 切片中还支持负数，以便从列表末尾开始迭代。 例如，`mylist[-1]`将返回列表的最后一项。

### 还有更多...

NumPy 是一个非常有用且功能强大的库，但是我们应该注意一些非常重要的区别。 Python 中的列表数据类型与`numpy`数组完全不同。 Python 列表可以包含许多不同的数据类型，包括列表。 因此，以下示例列表是完全有效的：

```
python_list = ['bob' , 5.1, True, 1, [5, 3, 'sam'] ]
```

在幕后，Python 列表包含指向列表元素存储位置的指针。 要访问列表的第一个元素，Python 转到列表的存储位置并获取存储在该位置的第一个值。 该值是第一个元素的内存地址。 然后，Python 跳转到这个新的内存位置，以获取实际第一个元素的值。 因此，获取列表的第一个元素需要两次内存查找。

NumPy 数组非常类似于 C。它们必须包含单个数据类型，这允许将数组存储在连续的内存块中，这使读取数组的速度显着提高。 当读取数组的第一个元素时，Python 转到包含要检索的实际值的适当内存地址。 当需要数组中的下一个元素时，它紧挨着内存中第一个元素的位置，这使读取速度更快。

### 另请参见

*   [NumPy 文档](http://docs.scipy.org/doc/numpy/reference/)
*   [关于 NumPy 和 SciPy 的强大教程](http://www.engr.ucsb.edu/~shell/che210d/numpy.pdf)

## 分析和可视化美国的最高收入数据

* * *

现在，我们已经导入并探索了最高收入数据集，现在让我们深入研究特定国家并对其收入分配数据进行一些分析。 特别是，美国拥有与百分比最高的收入相关的出色数据，因此我们将在以下练习中使用美国的数据。 如果选择其他国家/地区来利用其数据集，请注意，可能需要使用不同的字段来进行相同的分析。

### 准备

为了进行分析，我们将创建一些辅助方法，在本章中将不断使用这些方法。 面向应用程序的分析通常会产生可重复使用的代码，这些代码执行单个任务，以便快速适应不断变化的数据或分析要求。 特别地，让我们创建两个帮助器函数：一个用于按特定国家/地区提取数据的函数，以及一个用于从一组特定行中创建时间序列的函数：

```
In [22]: def dataset(path, country="United States"): 
 ...: """ 
 ...: Extract the data for the country provided. Default is United States. 
 ...: """ 
 ...: with open(path, 'r') as csvfile: 
 ...: reader = csv.DictReader(csvfile) 
 ...: for row in filter(lambda row: row["Country"]==country,reader): 
 ...: yield row 
 ...: 

In [23]: def timeseries(data, column): 
 ...: """ 
 ...: Creates a year based time series for the given column. 
 ...: """ 
 ...: for row in filter(lambda row: row[column], data): 
 ...: yield (int(row["Year"]), row[column]) 
 ...: 
```

第一个函数使用 Python 的内置过滤器函数在特定国家/地区使用`csv.DictReader`过滤器遍历数据集。 第二个函数利用了`Year`列为数据创建时间序列这一事实，一个生成器为数据集中的特定列生成（年，值）元组。 请注意，此函数应在由数据集函数创建的生成器中传递。 现在，我们可以利用这两个功能对单个国家/地区的任何列进行一系列分析。

### 怎么做...

一般而言，美国的数据分为六组：

*   前 10％的收入份额
*   收入比例最高的 5％
*   收入比例最高的 1％
*   收入份额最高的 0.5％
*   收入份额最高的 0.1％
*   平均收入份额

这些组反映了在这些特定容器中收集的数据点的汇总。 一个简单快速的第一分析方法是，简单地绘制出每个最高收入组随时间变化的收入份额的这些百分比。 由于绘制多个时间序列将是一项常见的任务，因此让我们再次创建一个`helper`函数，该函数包装 matplotlib 并为传递给它的每个时间序列生成一个折线图：

```
In [24]: def linechart(series, **kwargs): 
 ...: fig = plt.figure() 
 ...: ax = plt.subplot(111) 
 ...: for line in series: 
 ...: line = list(line) 
 ...: xvals = [v[0] for v in line] 
 ...: yvals = [v[1] for v in line] 
 ...: ax.plot(xvals, yvals) 
 ...: if 'ylabel' in kwargs: 
 ...: ax.set_ylabel(kwargs['ylabel']) 
 ...: if 'title' in kwargs: 
 ...: plt.title(kwargs['title']) 
 ...: if 'labels' in kwargs: 
 ...: ax.legend(kwargs.get('labels')) 
 ...: return fig 
 ...: 
```

这个功能很简单。 它会创建一个`matplotlib.pyplot`图形以及轴子图。 对于系列中的每一行，它获得`x`轴值（请记住，我们的时间序列时间元组中的第一项是`Year`）作为元组的第一项，而 *y [* 轴，这是第二个值。 它将它们分成单独的生成器，然后将它们绘制在图形上。 最后，我们想要图表的任何选项，例如标签或图例，我们都可以简单地将其作为关键字参数传递，而我们的函数将为我们处理这些选项！ 以下步骤将引导您完成此面向应用程序分析的食谱。

为了生成图表，我们只需要在想要的列上使用时间序列函数，并将它们传递给`linechart`函数。 现在，这个简单的任务是可重复的，在接下来的几张图表中，我们将使用几次：

```
In [25]: def percent_income_share(source): 
 ...: """ 
 ...: Create Income Share chart 
 ...: """ 
 ...: columns = ( 
 ...: "Top 10% income share", 
 ...: "Top 5% income share", 
 ...: "Top 1% income share", 
 ...: "Top 0.5% income share", 
 ...: "Top 0.1% income share", 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: return linechart([timeseries(source, col) for col in columns], 
 ...: labels=columns, 
 ...: , 
 ...: ylabel="Percentage") 
 ...: 
 ...: 
```

注意，我也将这个图表的生成也包装在一个函数中。 这样，我们可以根据需要修改图表，该函数将包装图表的配置和生成。 该函数标识线系列的列，然后获取数据集。 对于每一列，它都会创建一个时间序列，然后使用我们的配置选项将这些时间序列传递给我们的`linechart`函数：

1.  要生成图，我们将输入参数定义为`percent_income_source function`：

```
In [26]: percent_income_share(data_file) 

 ...: 
Out[26]:
```

下面的屏幕快照显示了结果，在本章的其余部分中，您将使用类似的模式来使用函数来创建所需的图：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_02-1.png)

该图告诉我们，收入组的原始百分比倾向于朝同一方向移动。 当一组的收入增加时，另一组的收入也增加。 这似乎是一项很好的理智检查，因为收入最高的 0.1％人群也位于收入最高的 10％人群中，他们为每个分类箱的总体均值做出了很大贡献。 每条线之间也存在明显的，持久的差异。

2.  查看原始百分比很有用，但我们可能还想考虑相对于该收入组的平均百分比，百分比随时间的变化情况。 为此，我们可以计算每个组百分比的平均值，然后将所有组的值除以我们刚才计算的平均值。

由于均值归一化是我们可能要在一系列数据集上执行的另一个常见函数，因此我们将再次创建一个函数，该函数接受一个时间序列作为输入并返回一个新的时间序列，其值除以均值：

```
In [27]: def normalize(data): 

 ...: """ 

 ...: Normalizes the data set. Expects a timeseries input 
 ...: """ 
 ...: data = list(data) 
 ...: norm = np.array(list(d[1] for d in data), dtype="f8") 
 ...: mean = norm.mean() 
 ...: norm /= mean 
 ...: return zip((d[0] for d in data), norm) 
 ...: 
```

3.  现在，我们可以轻松编写另一个函数，这些函数接受这些列并计算平均归一化的时间序列：

```
In [28]: def mean_normalized_percent_income_share(source): 
 ...: columns = ( 
 ...: "Top 10% income share", 
 ...: "Top 5% income share", 
 ...: "Top 1% income share", 
 ...: "Top 0.5% income share", 
 ...: "Top 0.1% income share", 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: return linechart([normalize(timeseries(source, col)) for col in columns], 
 ...: labels=columns, 
 ...: , 
 ...: ylabel="Percentage") 
 ...: mean_normalized_percent_income_share(data_file) 
 ...: plt.show() 
 ...: 
```

请注意，除了执行归一化时，以下命令片段与上一个功能非常相似：

```
>>> fig = mean_normalized_percent_income_share(DATA) 
>>> fig.show()
```

前面的命令为我们提供了下图：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_03-1.png)

此图向我们显示，该组越富裕，我们倾向于在其收入中看到的百分比波动越大。

4.  数据集还将组的收入分为几类，例如包括资本收益的收益与没有资本收益的收益。 让我们看一下每个组的资本收益收入如何随时间波动。

另一个常见功能是计算两列之间的差异，并绘制结果时间序列。 计算两个 NumPy 数组之间的差异也非常容易，并且由于这对于我们的任务很常见，因此我们编写了另一个函数来完成这项工作：

```
In [29]: def delta(first, second): 

 ...: """ 

 ...: Returns an array of deltas for the two arrays. 
 ...: """ 
 ...: first = list(first) 
 ...: years = yrange(first) 
 ...: first = np.array(list(d[1] for d in first), dtype="f8") 
 ...: second = np.array(list(d[1] for d in second), dtype="f8") 
 ...: if first.size != second.size: 
 ...: first = np.insert(first, [0,0,0,0], [None, None, None,None]) 
 ...: diff = first - second 
 ...: return zip(years, diff) 
 ...: 
```

此外，以下是适当的帮助程序功能：

```
In [30]: def yrange(data): 
 ...: """ 
 ...: Get the range of years from the dataset 
 ...: """ 
 ...: years = set() 
 ...: for row in data: 
 ...: if row[0] not in years: 
 ...: yield row[0] 
 ...: years.add(row[0])
```

此函数再次从每个数据集创建 NumPy 数组，将数据类型转换为浮点型。 请注意，我们需要从一个数据集中获取年份列表，因此我们从第一个数据集中收集它。

5.  我们还需要记住，`first.size`必须与`second.size`相同，例如，每个数组都具有相同的维数。 计算差异，然后将年份再次压缩到数据中以形成时间序列：

```
In [31]: def capital_gains_lift(source): 
 ...: """ 
 ...: Computes capital gains lift in top income percentages over time chart 
 ...: """ 
 ...: columns = ( 
 ...: ("Top 10% income share-including capital gains", 
 ...: "Top 10% income share"), 
 ...: ("Top 5% income share-including capital gains", 
 ...: "Top 5% income share"), 
 ...: ("Top 1% income share-including capital gains", 
 ...: "Top 1% income share"), 
 ...: ("Top 0.5% income share-including capital gains", 
 ...: "Top 0.5% income share"), 
 ...: ("Top 0.1% income share-including capital gains", 
 ...: "Top 0.1% income share"), 
 ...: ("Top 0.05% income share-including capital gains", 
 ...: "Top 0.05% income share"), 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: series = [delta(timeseries(source, a), timeseries(source,b)) 
 ...: for a, b in columns] 
 ...: return linechart(series,labels=list(col[1] for col in 
 ...: columns), 
 ...: , 
 ...: ylabel="Percentage Difference") 
 ...: capital_gains_lift(data_file) 
 ...: plt.show() 
 ...: 
```

前面的代码将列存储为第一列和第二列两列的元组，然后使用 delta 函数计算两者之间的差。 像我们之前的图形一样，它随后会创建一个折线图，如下所示：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_04-1.png)

这很有趣，因为该图显示了资本收益收入随时间推移的波动性。 如果您熟悉美国的财务历史，则可以在此图表中看到著名股票市场的兴衰对资本收益收入的影响。

### 工作原理...

对大型数据集执行操作的最简单方法是使用 NumPy 的`array`类。 正如我们已经看到的，此类允许我们执行常见的运算，包括标量和数组之间的基本数学运算。 但是，将生成器转换为数组需要我们将数据加载到内存中。 Python 的内置`list`函数采用一个迭代器并返回一个列表。 这是必需的，因为 NumPy 数组必须知道数据的长度才能分配正确的内存量。 使用该数组，可以很容易地计算出平均值，然后在整个数组上执行除法等于标量的运算。 这会广播除法运算，以便将数组中的每个元素均除以均值。 本质上，我们是通过均值对数组元素进行归一化。 然后，我们可以将年与新计算的数据压缩在一起，并返回时间序列。

## 进一步分析美国的最高收入群体

* * *

到目前为止，在本章中，我们着重分析了一段时间内的收入百分比。 接下来，我们将通过查看数据集中其他有趣的数据，继续进行分析，特别是实际收入数据和构成这些数据的收入类别。

### 准备

如果您已完成先前的食谱*，并分析并可视化了美国*的最高收入数据，则应具备继续进行所需的所有操作。

### 怎么做...

通过以下步骤，我们将更深入地研究数据集并检查其他收入数字：

1.  该数据集还包含不同组别的按年平均收入。 让我们用图形表示它们，看看它们随着时间相对于彼此如何变化：

```
In [32]: def average_incomes(source): 
 ...: """ 
 ...: Compares percentage average incomes 
 ...: """ 
 ...: columns = ( 
 ...: "Top 10% average income", 
 ...: "Top 5% average income", 
 ...: "Top 1% average income", 
 ...: "Top 0.5% average income", 
 ...: "Top 0.1% average income", 
 ...: "Top 0.05% average income", 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: return linechart([timeseries(source, col) for col in 
 ...: columns], labels=columns, , 
 ...: ylabel="2008 US Dollars") 
 ...: average_incomes(data_file) 
 ...: plt.show()
```

由于我们具有创建折线图的基础，因此我们可以立即使用已有的工具分析此新数据集。 我们只需选择不同的列集合，然后相应地自定义图表即可！ 以下是结果图：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_05-1.png)

该图显示的结果非常引人入胜。 直到 1980 年代，富人的收入大约比低收入人群高了 1-150 万美元。 从 1980 年代开始，这种差距急剧增加。

2.  我们还可以使用`delta`功能来查看有钱人比普通美国人有多少钱：

```
In [33]: def average_top_income_lift(source): 

 ...: """ 
 ...: Compares top percentage avg income over total avg 
 ...: """ 
 ...: columns = ( 
 ...: ("Top 10% average income", "Top 0.1% average income"), 
 ...: ("Top 5% average income", "Top 0.1% average income"), 
 ...: ("Top 1% average income", "Top 0.1% average income"), 
 ...: ("Top 0.5% average income", "Top 0.1% average income"), 
 ...: ("Top 0.1% average income", "Top 0.1% average income"), 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: series = [delta(timeseries(source, a), timeseries(source, 
 ...: b)) for a, b in columns] 
 ...: return linechart(series,labels=list(col[0] for col in columns), 
 ...: ,ylabel="2008 US Dollars") 
 ...: 
```

除了选择列和利用已经添加到项目中的功能之外，我们还没有编写新代码。 这揭示了以下内容：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_06-1.png)

3.  在我们的上一次分析中，我们将展示另一种图表，以查看最富有的美国人的收入构成。 由于组成是基于百分比的时间序列，因此该任务的一个很好的图表是堆积区域。 再一次，我们可以利用时间序列代码并简单地添加一个函数来创建堆积面积图，如下所示：

```
In [34]: def stackedarea(series, **kwargs): 
 ...: fig = plt.figure() 
 ...: axe = fig.add_subplot(111) 
 ...: fnx = lambda s: np.array(list(v[1] for v in s), dtype="f8") 
 ...: yax = np.row_stack(fnx(s) for s in series) 
 ...: xax = np.arange(1917, 2008) 
 ...: polys = axe.stackplot(xax, yax) 
 ...: axe.margins(0,0) 
 ...: if 'ylabel' in kwargs: 
 ...: axe.set_ylabel(kwargs['ylabel']) 
 ...: if 'labels' in kwargs: 
 ...: legendProxies = [] 
 ...: for poly in polys: 
 ...: legendProxies.append(plt.Rectangle((0, 0), 1, 1, 
 ...: fc=poly.get_facecolor()[0])) 
 ...: axe.legend(legendProxies, kwargs.get('labels')) 
 ...: if 'title' in kwargs: 
 ...: plt.title(kwargs['title']) 
 ...: return fig 
 ...: 
```

前面的函数期望一组时间序列，其总百分比总计为 100。我们创建了一个特殊的匿名函数，该函数会将每个序列转换为 NumPy 数组。 NumPy `row_stack`函数创建一个垂直堆叠的数组序列； 这就是使用`subplot.stackplot`函数生成堆栈图的原因。 此功能的唯一另一个惊喜是需要使用图例代理来创建具有图例中堆栈图填充颜色的矩形。

4.  现在，我们来看看最富有的美国人的收入构成：

```
In [35]: def income_composition(source): 
 ...: """ 
 ...: Compares income composition 
 ...: """ 
 ...: columns = ( 
 ...: "Top 10% income composition-Wages, salaries andpensions", 
 ...: "Top 10% income composition-Dividends", 
 ...: "Top 10% income composition-Interest Income", 
 ...: "Top 10% income composition-Rents", 
 ...: "Top 10% income composition-Entrepreneurial income", 
 ...: ) 
 ...: source = list(dataset(source)) 
 ...: labels = ("Salary", "Dividends", "Interest", "Rent","Business") 
 ...: return stackedarea([timeseries(source, col) for col in columns], 
 ...: labels=labels, , 
 ...: ylabel="Percentage") 
 ...: 
```

前面的代码生成以下图：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_07-1.png)

如您所见，美国收入最高的 10％的人大部分收入是来自薪金收入。 但是，营业收入也起着很大的作用。 与本世纪末相比，股息在本世纪初的作用更大，利息和租金也是如此。 有趣的是，在 20 世纪上半叶，与企业家收入相关的收入百分比一直下降，直到 1980 年代，它再次开始增长，这可能是由于技术部门的原因。

### 工作原理...

该食谱确实有助于证明面向应用程序方法的价值。 我们继续提取执行单一任务的代码部分，并将其用作函数。 随着我们功能库的增加，我们的分析通常充满重复但略有不同的任务，变得比创建更复杂。 更好的是，这些单独的部分更易于测试和评估。 随着时间的流逝，我们将通过额外的分析，建立一个功能丰富且完全定制的工具库，这将大大加快未来的调查速度。

该食谱还揭示了如何创建 Python 代码以构建更多类似于 R 的分析。 在进行进一步评估时，我们利用了已经为数据集构建的功能和工具，并创建了新的功能和工具，例如以旧工具为基础的堆积面积函数。 但是，与面向分析的方法不同，这些工具现在存在于特定于数据的代码库中，该代码库可用于构建应用程序和报告，我们将在下一个食谱中看到。

## 使用 Jinja2 进行报告

* * *

可视化和图形非常适合识别数据集中的明显模式。 但是，由于趋势来自多种来源，因此需要更深入的报告，以及对不直接参与该项目的技术人员的描述。 面向应用程序的分析不是手动创建这些报告，而是利用模板语言在分析时动态构建文档。 Jinja2 是一个 Python 库，用于通过组合模板（通常是 HTML 文件）来生成文档，但它也可以是任何类型的文本文件，并带有上下文（用于填充模板的数据源）。 这种组合非常适合报告我们正在执行的分析。

### 准备

Jinja2 模板库应已安装并可以使用。

### 怎么做...

以下步骤将引导我们逐步使用 **Jinja2** 模板库创建灵活且吸引人的报告输出：

1.  Jinja2 很简单，并且具有熟悉的 Python 风格的语法（尽管它不是 Python）。 模板可以包括逻辑或控制流，包括迭代，条件和格式，这消除了使数据适应模板的需要。 一个简单的例子如下：

```
In [36]: from jinja2 import Template 
 ...: template = Template(u'Greetings, {{ name }}!') 
 ...: template.render(name='Mr. Praline') 
Out[36]: 'Greetings, Mr. Praline!'
```

2.  但是，我们应该将模板与 Python 代码分离，而应将模板存储为文本文件到我们的系统中。 Jinja2 提供了一个中央`Environment`对象，该对象用于存储配置和全局对象以从文件系统或其他 Python 包中加载模板：

```
In [37]: from jinja2 import Environment, PackageLoader, FileSystemLoader 
 ...: # 'templates' should be the path to the templates folder 
 ...: # as written, it is assumed to be in the current directory 
 ...: jinjaenv = Environment(loader = FileSystemLoader('templates')) 
 ...: template = jinjaenv.get_template('report.html')
```

在这里，Jinja2 环境被配置为在我们的 Python 模块的 templates 目录中查找模板文件。 另一个推荐的加载程序是`FileSystemLoader`，应将其作为搜索路径来查找模板文件。 在这种情况下，从 Python 模块中提取了名为`report.html`的模板，并准备好进行渲染。

渲染可以像`template.render(context)`一样简单，它将返回生成的输出的 unicode 字符串。 上下文应该是 Python 字典，其关键字是将在模板中使用的变量名。 或者，可以将上下文作为关键字参数传入； `template.render({'name':'Terry'})`等效于`template.render(name='Terry')`。 但是，对于大型模板（和大型数据集），使用`template.stream`方法效率更高。 它不会立即渲染整个模板，而是顺序评估每个语句并将其作为生成器产生。

3.  然后，可以将流传递到类似文件的对象，以将其写入磁盘或通过网络进行序列化：

```
template.stream(items=['a', 'b', 'c'],name='Eric').dump('report-2013.html')
```

这种看似简单的技术非常强大，尤其是与 JSON 模块结合使用时。 JSON 数据可以直接转储到 JavaScript 片段中，以用于 Web 上的交互式图表和可视化库，例如 **D3**，**Highcharts** 和 **Google Charts**。

4.  让我们来看一个使用世界上最高收入数据集的完整示例：

```
In [38]: import csv 

 ...: import json 
 ...: from datetime import datetime 
 ...: from jinja2 import Environment, PackageLoader, FileSystemLoader 
 ...: from itertools import groupby 
 ...: from operator import itemgetter 
 ...: 

In [39]: def dataset(path, include): 
 ...: column = 'Average income per tax unit' 
 ...: with open(path, 'r') as csvfile: 
 ...: reader = csv.DictReader(csvfile) 
 ...: key = itemgetter('Country') 
 ...: # Use groupby: memory efficient collection by country 
 ...: for key, values in groupby(reader, key=key): 
 ...: # Only yield countries that are included 
 ...: if key in include: 
 ...: yield key, [(int(value['Year']), 
 ...: float(value[column])) 
 ...: for value in values if value[column]] 
 ...: 
 ...: 

In [40]: def extract_years(data): 
 ...: for country in data: 
 ...: for value in country[1]: 
 ...: yield value[0] 
 ...: 
 ...: datetime.now().strftime("%Y%m%d") 
 ...: jinjaenv = Environment(loader = FileSystemLoader('templates')) 
 ...: template = jinjaenv.get_template('report.html') 
 ...: template.stream(context).dump(path) 
 ...: 

In [41]: def write(context): 
 ...: path = "report-%s.html" %datetime.now().strftime("%Y%m%d") 
 ...: jinjaenv = Environment(loader = FileSystemLoader('templates')) 
 ...:     template = jinjaenv.get_template('report.html') 
 template.stream(context).dump(path) 
In [40]: def main(source): 
 ...: # Select countries to include 
 ...: include = ("United States", "France", "Italy", 
 ...: "Germany", "South Africa", "New Zealand") 
 ...: # Get dataset from CSV 
 ...: data = list(dataset(source, include)) 
 ...: years = set(extract_years(data)) 
 ...: # Generate context 
 ...: context = { 
 ...: 'title': "Average Income per Family, %i - %i" 
 ...: % (min(years), max(years)), 
 ...: 'years': json.dumps(list(years)), 
 ...: 'countries': [v[0] for v in data], 
 ...: 'series': json.dumps(list(extract_series(data, years))), 
 ...: } 
 ...: 
 ...: 

In [42]: write(context) 
 ...: if __name__ == '__main__': 
 ...: source = '../data/income_dist.csv' 
 ...: main(source)
```

这是很多代码，所以让我们逐步进行一下。 数据集功能读取我们的 CSV 文件的“平均收入”列，并根据一组包含的国家/地区进行过滤。 它使用函数迭代`helper`和`groupby`，该迭代通过国家/地区字段收集 CSV 文件的行，这意味着我们将获得每个国家/地区的数据集。 `itemgetter`和`groupby`函数都是 Python 中常用的，内存安全的辅助函数，它们在大规模数据分析过程中会产生很多繁重的工作。

提取数据集后，我们有两种帮助方法。 第一个`extract_years`生成每个国家/地区的所有年份值。 这是必要的，因为并非所有国家/地区都具有数据集中每年的值。 我们还将使用此功能来确定模板的年份范围。 这将我们带到第二个函数`extract_series`，该函数将数据标准化，用 None 值替换空年份以确保我们的时间序列正确。

`write()`方法包装模板编写功能。 它创建一个名为`report-{date}.html`的文件，并添加当前日期以供参考。 它还将加载 Environment 对象，找到报告模板，并将输出写入磁盘。 最后，main 方法将所有数据和上下文收集在一起并连接功能。

5.  报告模板如下：

```
<html> 
<head> 
    <title>{{ title }}</title> 
</head> 
<body> 
    <div class="container"> 
        <h1>{{ title }}</h1> 
        <div id="countries"> 
            <ul> 
            {% for country in countries %} 
                <li>{{ country }}<li> 
            {% endfor %} 
            </ul>  
        </div> 
        <div id="chart"></div> 
    </div> 

    <script type="text/javascript" 
 src="http://codeorigin.jquery.com/jquery-
 2.0.3.min.js"></script> 
    <script src="http://code.highcharts.com/highcharts.js">
     </script> 
    <script type="text/javascript"> 
        $.noConflict(); 
        jQuery(document).ready(function($) { 
            $('#chart').highcharts({ 
                xAxis: { 
                    categories: JSON.parse('{{ years }}'), 
                    tickInterval: 5, 
                }, 
                yAxis: { 
                    title: { 
                        text: "2008 USD" 
                    } 
                }, 
                plotOptions: { 
                    line: { 
                        marker: { 
                            enabled: false 
                        } 
                    } 
                }, 
                series: JSON.parse('{{ series }}') 
            }); 
        }); 
    </script> 
</body> 
</html> 
```

前面的模板会在正确的位置填写标题，然后创建数据集中包含的国家的无序列表。 此外，它使用 Highcharts 创建交互式图表。 Highcharts 是基于选项的 JavaScript 图表库。 请注意，我们正在使用`JSON.parse`解析在 Python 中转储的 JSON 数据。 这样可以确保将 Python 数据类型转换为 JavaScript 数据类型时不会发生冲突。 在浏览器中打开报表时，它应类似于以下屏幕截图：

![](https://www.packtpub.com/graphics/9781787129627/graphics/C3_Diag.png)

### 工作原理...

在 Python 中执行分析和数据挖掘与 R 紧密并行，尤其是在使用 NumPy 库时。 像 R 一样，NumPy 也专为科学计算而设计，在处理多维数组时具有类似的功能集。 但是，一般来说，Python 需要花费更多的代码行，尤其是在使用 matplotlib 创建图表时。 这是由 Python 的通用数据方法引起的，特别是因为它用于许多问题领域，而不是专门用于统计分析，这也是 Python 的强项。

特别是，使用 Python 进行的数据分析倾向于采用面向应用程序的方法，通常涉及实时更新的实时数据或流数据，而不是对单个数据集进行分析。 这通常意味着用 Python 执行的分析利用诸如 NumPy 之类的工具进行快速原型制作和统计探索，但随后利用极其包容的标准库来处理数据管道的所有阶段中的数据。

### 还有更多...

有几种不同的 Python 模板语言，每种都有不同的方法将预定义的模板与数据结合起来以形成易于阅读的输出。 这些模板语言中的许多旨在用作 Web 应用程序框架的骨干，例如 Django 和 Flask，它们用于从数据库构造动态网页。 由于这些语言非常适合生成 HTML，因此使用这些工具进行报告可以轻松地从一次性报告转换为计划报告，再到从 Web 应用程序按需报告。 Jinja2 是 Flask 的主要模板语言，具有类似于 Django 的语法，使其成为将来实现的绝佳选择。

### 另请参见

*   对于数据源，请访问[这个页面](http://topincomes.g-mond.parisschoolofeconomics.eu/)
*   [《Python 上的模板》文章](https://wiki.python.org/moin/Templating)
*   [《什么是数据科学》文章](http://radar.oreilly.com/2010/06/what-is-data-science.html)
*   [在 OSX Mountain Lion 中设置 Python 和 Matplotlib 的文章](http://www.tapir.caltech.edu/~dtsang/python.html)

## 在 R 中重复分析

* * *

本简短的调查会议旨在使用 R 软件复制上一部分中讨论的大多数数据分析。 在不依赖任何 R 包的意义上，该部分是独立的。

### 准备

R 默认版本中可用的功能足以执行本章前面的分析。 `income_dist.csv`文件需要存在于当前工作目录中。

### 怎么做...

如下一个程序所示，可以很容易地逐步执行与`income_dist.csv`文件相关的分析。

1.  使用`read.csv`函数加载数据集`income_dist.csv`并使用函数`nrow`，`str`，`length`和`unique`等，以得到以下结果：

```
id <- read.csv("income_dist.csv",header=TRUE) 
nrow(id) 
str(names(id)) 
length(names(id)) 
ncol(id) # equivalent of previous line 
unique(id$Country) 
levels(id$Country) # alternatively 
min(id$Year) 
max(id$Year) 
id_us <- id[id$Country=="United States",]
```

首先将数据存储在 R 对象 ID 中。 我们看到数据集中有 2180 个观测值/行。 该数据集具有 354 个变量，使用两个函数`str`和`names`可以看到一些变量。 变量的数量也使用`ncol`和长度函数进行验证。 通过代码`id[id$Country=="United States",]`选择与美国相关的数据。 现在，我们首先使用图函数来获得平均所得税的第一视图，这是一个糟糕的图。

2.  使用`plot`功能，我们得到一个简单的显示，如下所示：

```
plot(id_us$Year , id_us$Average.income.per.tax.unit) 0
```

这里没有给出输出，因为我们打算即兴进行输出。 现在，我们使用`barplot`函数代替绘图。

3.  使用`barplot`功能以及适当的标签选择，可获得优雅的显示效果：

```
barplot(id_us$Average.income.per.tax.unit,ylim=c(0,60000), 

 ylab="Income in USD",col="blue",main="U.S. Average Income 1913-2008", 
 names.arg=id_us$Year)
```

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_03_008.png)

使用图形功能选项始终是一个好习惯。 例如，我们通过`ylim`指定 y 变量的范围，通过`ylab`指定 y 轴标签的范围，并通过 main 指定图形的标题。

为了进一步分析，我们继续只关注美国地区：

1.  如下面的配方*中对美国最高收入数据的分析，并在以下程序中的 R 中再现了*的可视化，显示了美国最高收入数据。 在美国地区进行子集设置后，我们使用 **`[`** 中的子集选择 10％，5％，1％，0.5％和 0.1％的特定变量。 新的 R 对象是`id2_us2`：

```
id2 <- read.csv("income_dist.csv",header=TRUE,check.names = F) 
# using the check.names=F option to ensure special characters in colnames 
id2_us <- id2[id$Country=="United States",] 
id2_us2 <- id2_us[,c("Top 10% income share", 
 "Top 5% income share", 
 "Top 1% income share", 
 "Top 0.5% income share", 
 "Top 0.1% income share")] 
row.names(id2_us2) <- id2_us$Year
```

2.  使用`ts`功能将 R 对象`id2_us2`转换为时间序列对象。 现在，对于这种特定的数据选择，我们使用下一部分 R 代码逐年对其进行可视化处理：

```
id2_us2 <- ts(id2_us2,start=1913,frequency = 1) 
windows(height=20,width=10) 
plot.ts(id2_us2,plot.type="single",ylab="Percentage",frame.plot=TRUE, 
 col=c("blue","green","red","blueviolet","purple")) 
legend(x=c(1960,1980),y=c(45,30),c("Top 10%","Top 5%","Top 1%","Top 0.5%","Top 0.1%"), 
 col = c("blue","green","red","blueviolet","purple"),pch="-")
```

请注意，对象`id2_us2`具有五个时间序列对象。 我们使用选项`plot.type="single"`将它们全部绘制在一个帧中。 图例和颜色用于增强图形显示的美观性。 产生的图形输出如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_09-1.png)

3.  使用定标数据重复前面的练习：

```
id2_scale <- scale(id2_us2) 
windows(height=20,width=10) 
plot.ts(id2_scale,plot.type="single",ylab="Percentage",frame.plot=TRUE, 
 col=c("blue","green","red","blueviolet","purple")) 
legend(x=c(1960,1980),y=c(2,1),c("Top 10%","Top 5%","Top 1%","Top 0.5%","Top 0.1%"), col = c("blue","green","red","blueviolet","purple"),pch="-")
```

输出如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_10-2.png)

4.  请注意，此显示使五个时间序列之间的比较更加容易。
5.  为了在*中复制 Python 分析，进一步分析 R 中的美国最高收入组*和配方，我们在代码的最后一个块中提供 R 代码并输出：

```
id2_us3 <- id2_us[,c("Top 10% income share-including capital gains", 
 "Top 10% income share", 
 "Top 5% income share-including capital gains", 
 "Top 5% income share", 
 "Top 1% income share-including capital gains", 
 "Top 1% income share", 
 "Top 0.5% income share-including capital gains", 
 "Top 0.5% income share", 
 "Top 0.1% income share-including capital gains", 
 "Top 0.1% income share", 
 "Top 0.05% income share-including capital gains", 
 "Top 0.05% income share") 
 ] 
id2_us3[,"Top 10% capital gains"] <- id2_us3[,1]-id2_us3[,2] 
id2_us3[,"Top 5% capital gains"] <- id2_us3[,3]-id2_us3[,4] 
id2_us3[,"Top 1% capital gains"] <- id2_us3[,5]-id2_us3[,6] 
id2_us3[,"Top 0.5% capital gains"] <- id2_us3[,7]-id2_us3[,8] 
id2_us3[,"Top 0.1% capital gains"] <- id2_us3[,9]-id2_us3[,10] 
id2_us3[,"Top 0.05% capital gains"] <- id2_us3[,11]-id2_us3[,12] 
id2_us3 <- ts(id2_us3,start=1913,frequency = 1) 
windows(height=20,width=10) 
plot.ts(id2_us3[,13:18],plot.type="single",ylab="Percentage",frame.plot=TRUE, 
 col=c("blue","green","red","blueviolet","purple","yellow")) 
legend(x=c(1960,1980),y=c(7,5),c("Top 10%","Top 5%","Top 1%","Top 0.5%", 
 "Top 0.1%","Top 0.05%"), 
 col = c("blue","green","red","blueviolet","purple","yellow"),pch="-")
```

图形输出如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/B05932_03_11-2.png)

### 还有更多...

R 和 Python 是最竞争，最引人注目的和最完整的软件中的两个。 在大多数情况下，可以在 R 中复制 Python 分析，反之亦然。 不用说，不可能获得另一软件的确切答案。 但是，这不是本食谱的目的。