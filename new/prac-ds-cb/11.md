## 第 11 章。德国信用数据分析

在本章中，我们将介绍以下食谱：

*   转换数据
*   可视化分类数据
*   判别分析以识别默认值
*   拟合逻辑回归模型
*   德国数据的决策树
*   决策树的精细方面

## 简介

* * *

贷款！ 借款人的负债和银行的资产！ 银行当然希望只提供贷款，而不提供任何储蓄计划，例如储蓄账户，定期存款，定期存款等。 原因很简单，银行必须在一段时间后向客户付款，如果他们的收入不足，就不能放弃利息。 尽管银行希望尽可能多地发放贷款，但是有很多理由永远不会以先到先得的方式发放贷款。 显而易见的原因很简单，那就是如果客户违约，银行就会脱颖而出，并且有机会为更好的客户服务。 显而易见的问题是，如何定义更好的客户，分析方法将在这里提供帮助。 一个实用的数据集是德国数据集，其中包括客户是否已完全还清贷款的最终状态以及许多其他重要变量。

已经进行了很多分析，现在它已成为分类问题的重要基准数据集。 它已在[这个页面](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data))中提供。 在许多研究工作中都已使用它，在撰写本文时，它的总访问量为 228982。 可以在[这个页面](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)中找到使用 R 软件从各种角度进行的分析。 可以在[这个页面](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)中找到更多详细信息。 有关德国信贷数据的深入分析，请参阅 **Tattar（2013）**。 我们将从`RSADBE`包中提取此数据集，并在下一部分中进行简单的转换。 此处提供了数据集的详细说明。

`GC`数据集包含 21 个变量的 1,000 个观察值。 该信用数据中的利息变量是贷款是好贷，客户完全还清了贷款额还是坏贷，并将此状态的信息放入变量`good_bad`中。 在这里，在 1,000 项观察中，有 700 项是不良贷款，而其余则是不良贷款。 还收集了大量重要的变量数据，这些数据提供了有关客户类型的信息。 附加变量包括定量（数字）变量和定性（类别）变量。 数值变量是每月持续时间（`duration`），信用额度（`credit`），按可支配收入的比例分期付款（`installp`），目前居住的持续时间（`resident`），年限（ `age`），在银行的现有信用数（`existcr`）和申请人的受抚养人数（`depends`）。 其他 21 个变量中的其余均为类别变量。

GC 数据集简化了分类变量的因子水平的数值表示，因此，大多数将其标识为整数变量，这是不合适的。 例如，当前支票帐户（`checking`）的状态简单地从 1-4 编号，而它们应表示因子水平`< 0 DM`，`0 <= ... < 200 DM`，`>= 200 DM`和`No Acc`。 下一节将修复所需的因子变量级别。

## 简单的数据转换

* * *

可从 **RSADBE** 1.0 版本获得的德国信用数据有一定的局限性。 包中的数据文件名为`GC`。 许多类别变量存储为整数类，这会影响整体分析。 同样，某些变量在这里并不重要，并且在从整数类转换为因子类之后，需要重新标记。 例如，可以在[这个页面](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data))上获取有关变量的详细信息。 在本节中，我们将使用数据集并进行必要的转换。

### 准备

读者将需要安装`RSADBE`程序包，该程序包由`GC`数据集组成。 如前所述，我们首先加载所有必备库：

```
library (data.table)
library (dplyr)
library (RSADBE)
library (rpart)
library (randomForestSRC)
library (ROCR)
library (plyr)
```

### 怎么做...

`RSADBE` R 包中提供`GC`数据集。 如前所述，数据集由许多整数变量组成，而这些整数是因子水平的指标。 例如，如前所述，我们需要将因子水平设置为`< 0 DM`，`0 <= ... < 200 DM`，`>= 200 DM`和`No Acc`，而不是 1-4。 需要使用功能`as.factor`和`revalue`来完成对 1,000 个观测值的重新标记：

1.  将`checking`变量从其当前的`integer`类转换为`factor`，然后应用`revalue`（来自`plyr`包）函数以获得所需的结果：

```
data(GC)
GC2 <-GC
GC2$checking <-as.factor(GC2$checking)
GC2$checking <-revalue(GC2$checking,c("1"="< 0 DM","2"="0 <= ... < 200 DM",
"3"=">= 200 DM","4"="No Acc"))
```

2.  将其他`integer`对象类似地转换为所需的`factor`对象：

```
GC2$history <-as.factor(GC2$history)
GC2$history <-revalue(GC2$history,c("0"="All Paid","1"="Bank paid", "2"="Existing paid","3"="Delayed", "4"="Dues Remain"))
GC2$purpose <-as.factor(GC2$purpose)
GC2$purpose <-revalue(GC2$purpose,
c("0"="New Car","1"="Old Car","2"="Furniture",
"3"="Television","4"="Appliance","5"="Repairs",
"6"="Education","8"="Retraining","9"="Business",
"X"="Others"))
GC2$savings <-as.factor(GC2$savings)
GC2$savings <-revalue(GC2$savings,
c("1"="< 100 DM ","2"="100-500 DM",
"3"="500-1000 DM","4"=">1000 DM",
"5"="Unknown"))
GC2$employed <-as.factor(GC2$employed)
GC2$employed <-revalue(GC2$employed,
c("1"="Unemployed","2"="1 Year","3"="1-4 Years",
"4"="4-7 Years","5"=">7 Years"))
GC2$marital <-as.factor(GC2$marital)
GC2$marital <-revalue(GC2$marital,
c("1"="Female S","2"="Female M/D","3"="Male M/D",
"4"="Male S"))
GC2$coapp <-as.factor(GC2$coapp)
GC2$coapp <-revalue(GC2$coapp,
c("1"="None","2"="Co-app","3"="Guarantor"))
GC2$property <-as.factor(GC2$property)
GC2$property <-revalue(GC2$property,
c("1"="Real Estate","2"="Building society",
"3"="Others","4"="Unknown"))
GC2$other <-NULL# because "none" is dominating frequency
GC2$housing <-as.factor(GC2$housing)
GC2$housing <-revalue(GC2$housing,c("1"="Rent","2"="Own",
"3"="Free"))
GC2$job <-as.factor(GC2$job)
GC2$job <-revalue(GC2$job,c("1"="Unemployed","2"="Unskilled","3"="Skilled",
"4"="Highly Qualified"))
GC2$telephon <-as.factor(GC2$telephon)
GC2$telephon <-revalue(GC2$telephon,c("1"="None","2"="Registered"))
GC2$foreign <-as.factor(GC2$foreign)
GC2$foreign <-revalue(GC2$foreign,c("1"="No","2"="Yes"))
```

请注意，现在已从`GC2`中删除了另一个对象。

### 工作原理...

数据并不总是采用易于分析的格式，在许多情况下可能需要进行微调。 在本食谱中，我们使用了先将整数对象转换为因子，然后适当地重新标记它的技术。 很容易进行许多数据重组，我们将根据需要使用它们。

### 还有更多...

`data.table` R 软件包也非常有用。 可以在同一对象上执行数据重组，因此，无需像在此创建`GC2`一样创建另一个对象。

## 可视化分类数据

* * *

可视化是任何探索性分析的重要方面。 假设我们没有有关客户历史的其他信息，而我们只知道在批准的千笔贷款中有 700 笔良好的贷款。 在这种情况下，对下一个客户的良好贷款还款的预测概率为 0.7。 当感兴趣的变量是数字变量时，我们可以绘制直方图，箱线图等，以更好地理解问题。 在这里，输出`good_bad`是一个因子变量，这样的绘图没有任何意义。 可以使用条形图获得对因子变量的分布的简单理解，在条形图中，我们将有两个条形，其长度反映了成比例的频率。 但是，从 x 轴标记为好和不好不会增加任何值的意义上来说，条形图是一维图。

当两个变量都是数值变量时，散点图将揭示两个变量之间的关系。 在我们的案例中，关注的主要变量`good_bad`是类别/因子变量，根据它绘制其他变量不会显示出关系的性质，因此我们需要不同类型的可视化技术。 分类变量可视化需要专门的技术，我们在此使用镶嵌图。 有关更多详细信息，请参阅 *Friendly and Meyer（2015）*。

### 准备

这里将需要使用先前配方中创建的 R 数据帧 **`GC2`** 。

### 怎么做...

1.  条形图和镶嵌图在此处获得，我们首先从前者开始。
2.  `barplot`功能提供所需的图形：

```
barplot(table(GC2$good_bad))
```

3.  视觉输出如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_001-2.jpg)

`barplot`是不良贷款和不良贷款数量的简单描述。 有关变量的其他信息总是有用的。 镶嵌图是多个变量的条形图的堆叠排列，它指示了两个类别变量之间的关系类型。 现在，我们将首先查看变量`housing`，`employed`和`checking`在不同类别中的好/坏贷款比例，然后使用有用的镶嵌图进行跟踪。

4.  使用函数`table`和`prop.table`，我们获得每个类别变量的好坏贷款百分比：

```
table(GC2$good_bad,GC2$housing)

## Rent Own Free
## bad 70 186 44
## good 109 527 64

prop.table(table(GC2$good_bad,GC2$housing),margin=2)

## Rent Own Free
## bad 0.3911 0.2609 0.4074
## good 0.6089 0.7391 0.5926
```

好/坏贷款比率是 700/300，现在我们看到，如果根据房屋是`Rent`，`Own`和`Free`将人口分为三部分，则这些部分中的好商品比例为 分别为 *0.6089* ， *0.7391* 和 *0.5926* 。 因此，在自己的部分中，我们看到的优质贷款比例要高于人口中的较高比例。 当然，其他两个部分的不良贷款比例也有所增加，尽管可以在这些部分中进一步进行即兴创作。

5.  类似地，下面给出`employed`和`checking`与贷款变量的比例表：

```
prop.table(table(GC2$good_bad,GC2$employed),margin=2)
## Unemployed 1 Year 1-4 Years 4-7 Years >7 Years
## bad 0.3710 0.4070 0.3068 0.2241 0.2530
## good 0.6290 0.5930 0.6932 0.7759 0.7470

prop.table(table(GC2$good_bad,GC2$checking),margin=2)
## < 0 DM 0 <= ... < 200 DM >= 200 DM No Acc
## bad 0.4927 0.3903 0.2222 0.1168
## good 0.5073 0.6097 0.7778 0.8832
```

从前面的比例表中可以清楚地看出，如果申请人有 4 年以上的工作经验，那么还贷的可能性就比使用变量所确定的其他部分要高。 同样，如果`checking`贷款金额为`>= 200 DM`或`No Acc`，则良好的还款比例更高。 如果读者希望将数字可视化，可以在此处使用镶嵌图。

6.  可以很容易地获得两个分类变量的镶嵌图：

```
windows(height=15,width=10)
par(mfrow=c(3,1))
mosaicplot(~good_bad+housing,GC2)
mosaicplot(~good_bad+employed,GC2)
mosaicplot(~good_bad+checking,GC2)
```

7.  生成的镶嵌图如下所示：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_002-2.jpg)

比例可以很好地反映在镶嵌图上，因此我们在这里有一种有效的可视化方法。

### 工作原理...

R 函数`table`对于理解分类变量非常重要，它会根据因子水平对频率进行计数。 当`prop.table`应用于数组/表时，我们获得的列比例为 margin = 2。

马赛克图和条形图在分类数据分析中提供了直观的见解。 有了最初的印象，我们现在可以为统计方法建立统计技术，以识别客户最终会成为好付款人还是违约人。

## 判别分析

* * *

**判别分析**是最早的统计方法之一，用于将观察结果分类为不同的人群。 与许多早期的统计学先驱著作一样，这项技术也是伟大的 *R. A. Fisher 爵士*发明的。 判别分析的理论超出了本书的范围。 我们将只满足于使用`MASS`包中的`lda`函数。 在将`lda` R 技术应用于德国信用数据之前，我们将首先将其应用于`iris`数据集，这也受到费舍尔的欢迎。 在将该方法应用于`iris`数据集之后，我们将其应用于德国信用数据问题。

### 准备

默认 R 软件满足`iris`数据集和`MASS`包的要求。 读者需要像第一部分一样准备好`GC2`数据帧。

### 怎么做...

我们通过简单的功能对`iris`数据集有了初步的了解。 在此数据集中，我们有五个变量`Sepal.Length`，`Sepal.Width`，`Petal.Length`，`Petal.Width`和`Species`。 我们有三种类型的虹膜种类`setosa`，`versicolor`和`virginica`需要通过萼片和花瓣的长度和宽度来识别：

1.  从`datasets`包中加载`iris`对象，并使用`str`，`summary`和`pairs`函数获得初步了解：

```
data(iris)
str(iris)

## 'data.frame': 150 obs. of 5 variables:
## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
## $ Species : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...

summary(iris)

## Sepal.Length Sepal.Width Petal.Length Petal.Width
## Min. :4.30 Min. :2.00 Min. :1.00 Min. :0.1
## 1st Qu.:5.10 1st Qu.:2.80 1st Qu.:1.60 1st Qu.:0.3
## Median :5.80 Median :3.00 Median :4.35 Median :1.3
## Mean :5.84 Mean :3.06 Mean :3.76 Mean :1.2
## 3rd Qu.:6.40 3rd Qu.:3.30 3rd Qu.:5.10 3rd Qu.:1.8
## Max. :7.90 Max. :4.40 Max. :6.90 Max. :2.5
## Species
## setosa :50
## versicolor:50
## virginica :50
##pairs(iris[,-5]) # Output suppressed
```

2.  初步摘要给出了有关变量范围和其他基本摘要的想法。 希望有每种类型的物种的摘要，由对函数标识的散点图矩阵指示至少存在两种​​不同的物种。

3.  现在，在`iris`数据集上应用`MASS`包中的`lda`函数：

```
iris_lda <-lda(Species~.,iris)
iris_lda

## Call:
## lda(Species ~ ., data = iris)
##
## Prior probabilities of groups:
## setosa versicolor virginica
## 0.3333 0.3333 0.3333
##
## Group means:
## Sepal.Length Sepal.Width Petal.Length Petal.Width
## setosa 5.006 3.428 1.462 0.246
## versicolor 5.936 2.770 4.260 1.326
## virginica 6.588 2.974 5.552 2.026
##
## Coefficients of linear discriminants:
## LD1 LD2
## Sepal.Length 0.8294 0.0241
## Sepal.Width 1.5345 2.1645
## Petal.Length -2.2012 -0.9319
## Petal.Width -2.8105 2.8392
##
## Proportion of trace:
## LD1 LD2
## 0.9912 0.0088
```

4.  通过运行行`lda(Species~.,...)`，我们要求 R 通过公式`.~.`创建`lda`对象，其中物类是需要使用数据集中所有其他变量进行识别的组指示符。 在这里，我们有两个线性判别函数，它是萼片和花瓣的四个变量的长度和宽度的线性组合。 第一个线性判别函数是

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_003.png)

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_004.png)

5.  而第二个是

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_005.png)

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_006.png)

6.  重要的是，第一个判别式本身在这里解释了 99％的痕迹，并且看起来足以识别这三个组。 现在，我们来看看在这三个物种中判别式的分数如何。
7.  预测判别分数，并将直方图用于三种物种的分数：

```
iris_lda_values <-predict(iris_lda)
windows(height=20,width=10)
ldahist(iris_lda_values$x[,1],g=iris$Species)
```

8.  结果图如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_007-2.jpg)

9.  根据判别分数，我们可以清楚地看到三个不同的组。 最后，我们检查分类是否错误。
10.  使用`table`功能，评估该技术的性能：

```
table(predict(iris_lda)$class)

## setosa versicolor virginica
## 50 49 51

table(iris$Species,predict(iris_lda)$class)

## setosa versicolor virginica
## setosa 50 0 0
## versicolor 0 48 2
## virginica 0 1 49
```

11.  注意，在预测中使用函数表可以得出每个物种的频率。 但是，它不能告诉我们正确地预测了哪种原始鸢尾属植物。 将表格与原始类别和预测类别一起使用会给我们带来错误分类计数。 总体而言， *3/150 = 0.02％*错误看起来非常令人印象深刻。 接下来，我们将此技术应用于德国信用数据。
12.  `lda`功能现已应用于 **`GC2`** ：

```
GB_lda <-lda(good_bad~.,GC2)
GB_lda

## Call:
## lda(good_bad ~ ., data = GC2)
##
## Prior probabilities of groups:
## bad good
## 0.3 0.7
##

## Coefficients of linear discriminants:
## LD1
## checking0 <= ... < 200 DM 3.808e-01
## checking>= 200 DM 9.029e-01
## checkingNo Acc 1.317e+00

## telephonRegistered 2.159e-01
## foreignYes 7.212e-01

table(predict(GB_lda)$class)

##
## bad good
## 244 756

table(GC2$good_bad,predict(GB_lda)$class)

 ##
## bad good
## bad 158 142
## good 86 614
```

我们可以看到`lda`技术无法识别出将近 50％的不良贷款。 因此，在本章的其余部分中，我们需要对其进行改进并使用不同的方法。

### 工作原理...

`MASS`程序包中的`lda`功能可用于进行线性判别分析。

### 另请参见

有关判别分析技术的详细信息，请阅读 *McLachlan（1992）*。

## 划分数据和 ROC

* * *

如果使用整个数据集来构建模型，则可能是我们过度训练了模型。 结果是，对于未知情况，模型的真实性能没有引起注意。 从本质上讲，我们需要为信用问题建立一个良好的模型，如果在新的或无法预料的情况下业绩未知，那么怀疑论势必会渗入我们的脑海。 好的做法是将可用数据分成三个区域：（i）用于构建模型的数据，（ii）用于验证模型的数据，以及（iii）用于测试模型的数据。 因此，针对问题建立了一组模型，然后对数据的经过验证的部分进行评估，然后选择在此阶段表现最佳的模型作为数据的测试部分。 可以轻松地在三个区域中进行数据分区，并且我们可以快速显示如何对德国信贷数据进行分区。

接收操作曲线或 ROC 是访问分类模型性能的非常有效的工具。 我们从 Tattar（2013）的第 7 章*中大量借用。 在许多分类模型中，如果预测的成功概率大于 0.5，则将该观察结果预测为成功观察结果，否则为失败观察结果。 至少通过训练和验证数据，我们知道观测值的真实标记，因此将真实标记与预测标记进行比较是有意义的。 在理想情况下，我们希望预测标签与实际标签完全匹配。 但是，实际上，这种情况很少发生，这意味着当真正的标签实际上是失败/成功时，有一些观察结果会被预测为成功/失败。*

换句话说，我们会犯错误！ 可以将这些注释以被广泛称为**混淆矩阵**的表格的形式放置。

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_008.png)

我们考虑以下指标以便在各个模型之间进行比较：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_009.png)

现在，当我们遇到班级不平衡的问题时，具有非常高的准确性和精确度会更容易，但这将毫无用处。 例如，如果在 100 万个观察中有 100 个欺诈性交易，则将全部识别为良好交易的分类器将具有 99.99％以上的准确性和非常高的精度。 但是，此类模型甚至无法识别单个欺诈交易。 在这种情况下，ROC 方法非常有用。 ROC 构造需要两个指标：**真阳性率**（ **tpr** ）和**假阳性率**（ **fpr** ）：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_010.png)

通过绘制 **tpr** 对 **fpr 绘制 ROC 图。** 对角线与随机分类器的性能有关，因为它仅显示是或否，而无需查看观察的任何特征。 任何好的分类器都必须位于此行上方，而不是显示在行上方。 尽管分类器未知，但它似乎比随机分类器更好。 与竞争性分类器相比，ROC 曲线很有用，因为如果一个分类器始终位于另一个分类器之上，那么我们选择前者。 与 ROC 相关的另一个重要指标是**曲线下的面积**（ **AUC** ）。 AUC 越高，模型越好，它是介于 0 和 1 之间的数字。

### 准备

正如本章前面部分所准备的，我们需要当前会​​话中的`GC2`对象。

### 怎么做...

可重现性是学习初期的重要方面。 我们为数据的随机分割设置了一个种子，以使读取的结果与在 R 环境中运行它们所获得的结果相同。

1.  使用`set.seed`可再现：

```
set.seed(1234567)
```

2.  创建三个标签`Train`，`Validate`和`Test`：

```
data_part_label <-c("Train","Validate","Test")
```

3.  现在，从向量`data_part_label`进行 1000 次采样（替换）（概率为 0.6、0.2 和 0.2），并相应地提取子集`GC2`：

```
indv_label =sample(data_part_label,size=1000,replace=TRUE,prob
=c(0.6,0.2,0.2))
GC_Train <-GC2[indv_label=="Train",]
GC_Validate <-GC2[indv_label=="Validate",]
GC_Test <-GC2[indv_label=="Test",]
```

现在，我们在`GC_Train`中大约有 600 个观测值，在`GC_Validate`和`GC_Test`中每个都有 200 个观测值。

4.  从`ROCR`包运行示例以提高性能：

```
example(performance)
```

在屏幕上看到的图表中，您会发现`tpr`与`tfr`相对。 理想的分类器将从 y 轴上的 1 开始。 为了进行跨模型比较，我们更喜欢 ROC 曲线始终高于其他曲线的模型。 例如，我们想为数据集的`Train`和`Validate`部分生成 ROC 曲线。 通常，`Train`部分的 ROC 曲线会好于`Validate`部分的 ROC 曲线。

## 拟合逻辑回归模型

* * *

仅当自变量/协变量的集合遵循多元正态分布时，判别分析技术才能很好地发挥作用。 在开始时，它不能通过排除类别变量来显示灵活性。 众所周知，许多经济变量（例如工资，储蓄等）不遵循正态分布，而且总体上也存在偏差。 因此，多元正态分布的假设相当局限，我们需要一个用于分类问题的通用框架。 *Logistic 回归模型*提供了非常重要的一类模型。 实际上，众所周知它具有非常好的理论特性。 例如，在理论上已知，在自变量遵循多元正态分布的情况下，逻辑回归模型可提供与判别分析一样高的准确性。 逻辑回归模型是重要指数族的成员，属于广义线性模型*的一类。* 给出独立观察的向量：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_011.png)

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_012.png)

这里，我们有 *k* 个自变量，而随机变量 *Y* 是二元随机变量，并且是逻辑回归模型的因变量，请参阅《 Tattar（2013 年》第 7 章 ）或 *Tattar 等人的第 17 章。 （2016）*了解更多详细信息和深度。 为了我们的目的，我们现在仅使用 R `glm`中的函数。 ROC 软件包`ROCR`和`pROC`对于执行与其相关的任务很有用。 首先，我们将拟合逻辑回归模型并获得摘要以找出哪些变量是重要的。

### 准备

除了工作会话中的`GC2`对象外，我们还需要 ROC 包`ROCR`和`pROC`来完成会话。

### 怎么做...

现在，我们将在这里构建一个逻辑回归模型：

1.  使用`glm`函数，我们为`training`数据集`GC_Train`建立了逻辑回归模型，然后应用`summary`函数来获取拟合模型的详细信息：

```
GC_Logistic <-glm(good_bad~.,data=GC_Train,family='binomial')
summary(GC_Logistic)

##
## Call:
## glm(formula = good_bad ~ ., family = "binomial", data = GC_Train)
##
## Deviance Residuals:
## Min 1Q Median 3Q Max
## -2.428 -0.725 0.374 0.715 2.222
##
## Coefficients:
## Estimate Std. Error z value Pr(>|z|)
## (Intercept) 1.42e+00 1.35e+00 1.05 0.2927
## checking0 <= ... < 200 DM 1.24e-01 2.86e-01 0.44 0.6634
## checking>= 200 DM 5.08e-01 4.81e-01 1.06 0.2913
## checkingNo Acc 1.65e+00 3.06e-01 5.40 6.7e-08 ***
## duration -2.95e-02 1.22e-02 -2.43 0.0153 *
## historyBank paid -2.20e-01 6.78e-01 -0.33 0.7451
## historyExisting paid 3.67e-01 5.29e-01 0.69 0.4880
## historyDelayed 3.93e-01 5.83e-01 0.67 0.4999
## historyDues Remain 1.47e+00 5.46e-01 2.69 0.0071 **
## purposeOld Car 1.58e+00 5.07e-01 3.12 0.0018 **
## purposeFurniture 8.66e-01 3.58e-01 2.42 0.0156 *
## purposeTelevision 6.42e-01 3.20e-01 2.01 0.0448 *
## purposeAppliance 6.17e-01 1.06e+00 0.58 0.5594
## purposeRepairs -3.12e-01 7.32e-01 -0.43 0.6699
## purposeEducation -5.74e-01 5.42e-01 -1.06 0.2896
## purposeRetraining 1.50e+01 8.96e+02 0.02 0.9867
## purposeBusiness 7.10e-01 4.36e-01 1.63 0.1032
## purposeOthers 1.50e+01 8.37e+02 0.02 0.9857
## amount -1.09e-04 5.74e-05 -1.90 0.0569 .
## savings100-500 DM 3.22e-01 3.77e-01 0.85 0.3931
## savings500-1000 DM 2.13e-01 4.69e-01 0.46 0.6491
## savings>1000 DM 7.19e-01 6.49e-01 1.11 0.2685
## savingsUnknown 1.24e+00 3.65e-01 3.39 0.0007 ***
## employed1 Year 1.69e-01 5.69e-01 0.30 0.7662
## employed1-4 Years 2.50e-01 5.53e-01 0.45 0.6518
## employed4-7 Years 7.69e-01 6.01e-01 1.28 0.2005
## employed>7 Years 2.62e-01 5.50e-01 0.48 0.6345
## installp -3.34e-01 1.17e-01 -2.84 0.0045 **
## maritalFemale M/D -2.30e-01 5.33e-01 -0.43 0.6661
## maritalMale M/D 5.49e-01 5.29e-01 1.04 0.2987
## maritalMale S 1.57e-01 6.18e-01 0.25 0.7992
## coappCo-app 4.02e-01 6.05e-01 0.66 0.5069
## coappGuarantor 1.34e+00 5.78e-01 2.33 0.0201 *
## resident 4.00e-02 1.10e-01 0.36 0.7162
## propertyBuilding society -4.23e-01 3.31e-01 -1.28 0.2019
## propertyOthers -2.47e-01 3.10e-01 -0.80 0.4250
## propertyUnknown -8.60e-01 5.66e-01 -1.52 0.1284
## age 1.32e-02 1.14e-02 1.16 0.2472
## housingOwn 1.28e-01 3.27e-01 0.39 0.6946
## housingFree 4.41e-01 6.27e-01 0.70 0.4824
## existcr -3.32e-01 2.57e-01 -1.29 0.1970
## jobUnskilled -5.35e-01 8.72e-01 -0.61 0.5395
## jobSkilled -4.76e-01 8.47e-01 -0.56 0.5739
## jobHighly Qualified -6.57e-01 8.65e-01 -0.76 0.4476
## depends -5.90e-01 3.25e-01 -1.81 0.0696 .
## telephonRegistered 2.99e-01 2.61e-01 1.14 0.2526
## foreignYes 1.47e+00 1.08e+00 1.36 0.1739
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 734.00 on 598 degrees of freedom
## Residual deviance: 535.08 on 552 degrees of freedom
## AIC: 629.1
##
## Number of Fisher Scoring iterations: 14
```

2.  与常规回归模型一样，将具有 *k* 因子的因子变量转换为 *k-1* 新变量。 这里，统计上无关紧要的变量是`employed`，`marital`，`resident`，`property`，`age`，`housing`，`exist`，`job`，`telephone`和`foreign`。 也就是说，在指定的 20 个变量中，有 10 个是不重要的，而其他的则是重要的。 在因子变量的情况下，如果任何一个水平是显着水平，则总体变量也将是显着水平。 经过 14 次迭代后，基础算法已收敛。 接下来，我们将研究训练部分模型的准确性。

3.  使用`table`函数，我们计算模型的准确性如下：

```
table(GC_Train$good_bad)

##
## bad good
## 181 418

table(GC_Train$good_bad, ifelse(predict(GC_Logistic,type="response")>0.5,"good","bad"))

 ##
## bad good
## bad 96 85
## good 46 372
```

4.  在训练数据集中，我们有 181 笔不良贷款，逻辑回归模型可以正确识别其中的 96 笔，准确率略高于 50％。 当然，需要提高准确性。 但是，我们将首先检查模型在未用于构建模型的数据点上的性能以及进行 ROC 分析。
5.  对于训练和验证分区， **`predict`** 通过拟合的 Logistic 回归模型进行类别识别。 同样，使用`ROCR`包中的`prediction`和`performance`功能来设置 ROC 曲线：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_013.png)

6.  结果图如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_014-2.jpg)

7.  从 ROC 曲线可以看出，在不可见的情况或验证部分中，逻辑回归的性能下降了，正如预期的那样。 接下来，我们在两个区域中为模型计算曲线度量下的面积。

8.  使用`pROC`软件包中的`roc`函数计算曲线下面积：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_015.png)

9.  因此，逻辑回归模型在训练部分比验证部分具有更高的 AUC。 存在许多改进逻辑回归模型的方法，例如，可以研究模型选择问题，多重共线性问题等。 但是，这里不需要逻辑回归模型中的详细离题。 在此，AUC 差为 *0.836-0.72 = 0.116* ，并且看起来非常高。 理想的是找到那些差异尽可能小的模型，这将意味着该模型已经了解了特征/模式，并且也能够很好地归纳。 在下一节中，我们将快速查看决策规则，在下一节中，我们将查看规则的生成方式。

### 工作原理...

`glm`功能非常通用，可用于拟合广义线性模型类别中的模型。 在这里，我们使用带有选项`family='binomial'`的逻辑回归模型进行拟合。 `summary`功能提供了拟合模型的详细信息。 `table`功能用于在训练中访问拟合模型的准确性，并验证部分数据。 给定独立变量的值，`predict`函数返回概率 P（Y = 1）。 `ROCR`软件包中的`prediction`和`performance`函数有助于设置 ROC 曲线，而`pROC`软件包中的`roc`函数用于计算 AUC。

### 另请参见

有关更多详细信息，请尝试`?glm, library(help=ROCR)`和`library(help=pROC)`。

## 决策树和规则

* * *

逻辑回归模型是一种强大的技术。 对于从业者而言，它在 p 值，预测阈值等方面存在一些困难。 决策规则提供了一个简单的框架，从业者应仅查看某些变量和值即可做出决策。 例如，如果客户致电银行服务台并试图确定他们是否有资格获得贷款，则呼叫中心员工会询问一些详细信息，例如年龄，收入，性别，现有贷款等，并告知 他们是否有资格获得贷款。 通常，使用一组决策规则来得出这样的决策。 同样，如果急诊患者在怀疑有心脏相关问题的情况下前往医院，则一套简单的规则可能有助于确定是胃病还是发作，在后一种情况下，医院可以开始必要的准备工作 因为每一分钟对诊断都至关重要。 重要的问题是如何得出这样一组决策规则。

决策规则很容易从决策树中得出，我们来看`rpart`示例。 我们将首先构建一个分类树，然后可视化决策树。 从树中提取决策规则，然后我们将使用表函数查看每个终端节点上的百分位数拆分。

### 准备

我们将需要`rpart`包中的`kyphosis`数据集。

### 怎么做...

1.  使用`kyphosis`数据，我们将了解决策树和规则：
2.  从`rpart`包中加载`kyphosis`数据集：

```
library(rpart)
data(kyphosis)
```

3.  使用`rpart`函数构建分类树并可视化决策树：

```
kyphosis_rpart <-rpart(Kyphosis~.,kyphosis)
plot(kyphosis_rpart,uniform=TRUE)
text(kyphosis_rpart)
```

4.  结果决策树如下：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_016-2.jpg)

5.  可以使用 **`rattle`** 包中的 **`asRules`** 函数提取树的规则：

```
asRules(kyphosis_rpart)

 ##
## Rule number: 3 [Kyphosis=present cover=19 (23%) prob=0.58]
## Start< 8.5
##
## Rule number: 23 [Kyphosis=present cover=7 (9%) prob=0.57]
## Start>=8.5
## Start< 14.5
## Age>=55
## Age< 111
##
## Rule number: 22 [Kyphosis=absent cover=14 (17%) prob=0.14]
## Start>=8.5
## Start< 14.5
## Age>=55
## Age>=111
##
## Rule number: 10 [Kyphosis=absent cover=12 (15%) prob=0.00]
## Start>=8.5
## Start< 14.5
## Age< 55
##
## Rule number: 4 [Kyphosis=absent cover=29 (36%) prob=0.00]
## Start>=8.5
## Start>=14.5
```

6.  我们可以很容易地获得每个终端节点的案例数的计数，如下所示。
7.  使用`rpart`函数的`where`变量查找为案例分配了哪个终端节点：

```
kyphosis$where <-kyphosis_rpart$where
table(kyphosis$Kyphosis,kyphosis$where) ##
## 3 5 7 8 9
## absent 29 12 12 3 8
## present 0 0 2 4 11
```

8.  现在，这些数字也可以通过简单的 **`table`** 功能获得。 首先，我们将`data.frame`对象转换为`data.table`对象。
9.  将`data.frame`后凸畸变转换为`data.table`对象：

```
K2 <-data.table(kyphosis)
```

10.  由于前面的树形图表明如果起始值大于 12.5，则个体中将不会出现驼背症，因此我们对其进行检查。
11.  使用`data.table`结构，通过 **`Start`** 变量找到比例计数：

```
K2[,prop.table(table(Kyphosis))]

## Kyphosis
## absent present
## 0.7901 0.2099
```

12.  同样，在每个终端节点上验证比例计数：

```
K2[Start>=12.5,prop.table(table(Kyphosis))]

## Kyphosis
## absent present
## 0.95652 0.04348

K2[Start <12.5&Age <=35,prop.table(table(Kyphosis))]

## Kyphosis
## absent present
## 0.9 0.1

K2[Start <12.5&Age >35&Number <4.5,prop.table(table(Kyphosis))]

## Kyphosis
## absent present
## 0.5833 0.4167

K2[Start <12.5&Age >35&Number >=4.5,prop.table(table(Kyphosis))]

## Kyphosis
## absent present
## 0.3077 0.6923
```

因此，决策树创建数据集的分区，其中每个终端节点都具有尽可能高的因子变量大小写。 通常，决策树查看每个变量的不同值，并将数据相应地划分为不同的区域。 然后，它访问每个分区的性能，并选择该拆分，从而在每个终端节点上获得最大的精度增益。 因此，将数据递归拆分为多个区域，并结束该过程，直到每个终端节点都包含尽可能多的纯节点。

接下来，我们将为德国信贷数据构建决策树。

### 工作原理...

`rpart`软件包有助于构建分类，回归和生存树。 使用`plot`功能可以轻松可视化决策树。 我们已经从`rattle`包中使用`asRules`函数提取了决策树的规则。

### 另请参见

可以使用多个包（例如`partykit`，`tree`等）在 R 中构建决策树。

## 德国数据的决策树

* * *

我们为德国数据拟合了逻辑回归模型。 现在，我们将为其创建一个决策树。

### 准备

这里将需要`GC2`对象以及已分区的数据。 而且，需要拟合的逻辑回归模型。

### 怎么做...

我们将使用`rpart`包及其功能来创建决策树：

1.  创建决策树并按以下方式绘制：

```
GC_CT <-rpart(good_bad~.,data=GC_Train)
windows(height=20,width=20)
plot(GC_CT,uniform =TRUE);text(GC_CT)
```

2.  决策树图如下所示：

![](https://www.packtpub.com/graphics/9781787129627/graphics/image_11_017-2.jpg)

3.  需要评估拟合树的属性。
4.  检查复杂度参数和拟合树的重要变量：

```
table(GC_Train$good_bad,predict(GC_CT,type="class"))

##
## bad good
## bad 107 74
## good 32 386

GC_CT$cptable

## CP nsplit rel error xerror xstd
## 1 0.06262 0 1.0000 1.0000 0.06209
## 2 0.02486 3 0.8122 0.9503 0.06118
## 3 0.02210 6 0.7348 1.0055 0.06219
## 4 0.01842 8 0.6906 0.9724 0.06159
## 5 0.01657 12 0.6022 0.9779 0.06170
## 6 0.01000 13 0.5856 0.9724 0.06159

GC_CT$variable.importance

## checking duration amount history savings purpose coapp property
## 29.4516 15.0985 12.8465 11.2774 10.8025 9.7595 7.2114 6.7423
## employed housing age installp existcr job marital resident
## 6.7003 6.1063 3.6083 2.8071 1.6281 1.4417 1.3372 0.9983
```

5.  因此，我们看到按重要性顺序排列的变量是检查，持续时间，数量，历史记录等。 在训练数据集中的 181 笔不良贷款中，我们使用 logistic 回归模型确定了 107 笔不良贷款，而只有 96 笔。 这是否确实是一种改进，将在以后评估。 现在，我们将完成 ROC 分析。
6.  与逻辑回归模型一样，我们首先拟合 ROC 曲线，然后将其与早期的逻辑回归解决方案进行比较：

```
 GC_CT_Train_Prob <-predict(GC_CT,newdata=GC_Train[,-21], type="prob")[,2]
GC_CT_Validate_Prob <-predict(GC_CT,newdata=GC_Validate[,-21], type="prob")[,2]
GB_CT_Train_roc <-roc(GC_Train$good_bad,GC_CT_Train_Prob)
GB_CT_Validate_roc <-roc(GC_Validate$good_bad,GC_CT_Validate_Prob)roc.test(GB_Logistic_Train_roc,GB_CT_Train_roc)

##
## DeLong's test for two correlated ROC curves
##
## data: GB_Logistic_Train_roc and GB_CT_Train_roc
## Z = 0.92, p-value = 0.4
## alternative hypothesis: true difference in AUC is not equal to 0
## sample estimates:
## AUC of roc1 AUC of roc2
## 0.8358 0.8206

roc.test(GB_Logistic_Validate_roc,GB_CT_Validate_roc)

##
## DeLong's test for two correlated ROC curves
##
## data: GB_Logistic_Validate_roc and GB_CT_Validate_roc
## Z = -0.2, p-value = 0.8
## alternative hypothesis: true difference in AUC is not equal to 0
## sample estimates:
## AUC of roc1 AUC of roc2
## 0.7198 0.7301
```

决策树的准确性获得更高的收益在统计上并不重要。 因此，逻辑回归模型和决策树的 ROC 曲线差别不大。 但是，如果我们忽略了 ROC 测试的结果，我们也可以说决策树具有更高的准确性。

### 工作原理...

`rpart`功能仍然有用。 此外，我们在书中首次应用了`roc.test`。

在决策树的上下文中已经取得了很大的进步，我们仅使用简单的决策树来限制自己。