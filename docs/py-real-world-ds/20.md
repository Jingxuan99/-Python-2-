# 二十、与数据库交互

数据分析始于数据。 因此，使用易于设置，操作且数据访问本身不会成为问题的数据存储系统是有益的。 简而言之，我们希望拥有易于嵌入到我们的数据分析过程和工作流中的数据库系统。 在本模块中，我们主要集中在数据库交互的 Python 方面，并且我们将学习如何将数据导入和导出 Pandas 数据结构。

有多种存储数据的方法。 在本章中，我们将学习与三个主要类别进行交互：文本格式，二进制格式和数据库。 我们将专注于两种存储解决方案，MongoDB 和 Redis。 MongoDB 是一个面向文档的数据库，易于入门，因为我们可以存储 JSON 文档，而无需预先定义架构。 Redis 是一种流行的内存数据结构存储，可以在其上构建许多应用。 可以将 Redis 用作快速键值存储，但是 Redis 也支持开箱即用的列表，集合，哈希，位数组甚至高级数据结构（例如 HyperLogLog）。

# 与文本格式的数据进行交互

文本是很好的媒介，它是一种交换信息的简单方法。 以下语句来自 *Doug McIlroy* 的引号：*编写处理文本流的程序，因为这是通用接口。*

在本节中，我们将开始在文本文件中读写数据。

## 从文本格式读取数据

通常，系统的原始数据日志存储在多个文本文件中，随着时间的推移，这些文本文件会累积大量信息。 幸运的是，在 Python 中与这些文件进行交互很简单。

pandas 支持多种功能，可将数据从文本文件读取到 DataFrame 对象中。 最简单的是`read_csv()`功能。 让我们从一个小的示例文件开始：

```pypy
$ cat example_data/ex_06-01.txt
Name,age,major_id,sex,hometown
Nam,7,1,male,hcm
Mai,11,1,female,hcm
Lan,25,3,female,hn
Hung,42,3,male,tn
Nghia,26,3,male,dn
Vinh,39,3,male,vl
Hong,28,4,female,dn

```

### 注意

`cat`是 Unix shell 命令，可用于将文件内容打印到屏幕上。

在前面的示例文件中，每一列用逗号分隔，第一行是标题行，其中包含列名。 要将数据文件读入 DataFrame 对象，我们键入以下命令：

```pypy
>>> df_ex1 = pd.read_csv('example_data/ex_06-01.txt')
>>> df_ex1
 Name  age  major_id     sex hometown
0    Nam    7         1    male      hcm
1    Mai   11         1  female      hcm
2    Lan   25         3  female       hn
3   Hung   42         3    male       tn
4  Nghia   26         3    male       dn
5   Vinh   39         3    male       vl
6   Hong   28         4  female       dn

```

我们看到`read_csv`函数使用逗号作为文本文件中各列之间的默认分隔符，并且第一行自动用作各列的标题。 如果要更改此设置，可以在示例文件没有标题行的情况下使用`sep`参数更改分隔的符号并设置`header=None`。

请参见以下示例：

```pypy
$ cat example_data/ex_06-02.txt
Nam     7       1       male    hcm
Mai     11      1       female  hcm
Lan     25      3       female  hn
Hung    42      3       male    tn
Nghia   26      3       male    dn
Vinh    39      3       male    vl
Hong    28      4       female  dn

>>> df_ex2 = pd.read_csv('example_data/ex_06-02.txt',
 sep = '\t', header=None)
>>> df_ex2
 0   1  2       3    4
0    Nam   7  1    male  hcm
1    Mai  11  1  female  hcm
2    Lan  25  3  female   hn
3   Hung  42  3    male   tn
4  Nghia  26  3    male   dn
5   Vinh  39  3    male   vl
6   Hong  28  4  female   dn

```

我们也可以使用等于选定行索引的`header`将设置为字幕行。 类似地，当我们想使用数据文件中的任何列作为 DataFrame 的列索引时，我们将`index_col`设置为该列的名称或索引。 我们再次使用第二个数据文件`example_data/ex_06-02.txt`进行说明：

```pypy
>>> df_ex3 = pd.read_csv('example_data/ex_06-02.txt',
 sep = '\t', header=None,
 index_col=0)
>>> df_ex3
 1  2       3    4
0
Nam     7  1    male  hcm
Mai    11  1  female  hcm
Lan    25  3  female   hn
Hung   42  3    male   tn
Nghia  26  3    male   dn
Vinh   39  3    male   vl
Hong   28  4  female   dn

```

除了这些参数，我们还有许多有用的参数，可以帮助我们更有效地将数据文件加载到 pandas 对象中。 下表显示了一些常用参数：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"> <col class="calibre18"></colgroup> 
| 

范围

 | 

价值

 | 

描述

 |
| --- | --- | --- |
| `dtype` | 类型名称或列类型的字典 | 设置数据或列的数据类型。 默认情况下，它将尝试推断最合适的数据类型。 |
| `skiprows` | 类列表或整数 | 要跳过的行数（从 0 开始）。 |
| `na_values` | 类列表或字典，默认为无 | 识别为`NA` / `NaN`的值。 如果通过了 dict，则可以在每个列的基础上进行设置。 |
| `true_values` | 列表 | 也要转换为布尔 True 的值列表。 |
| `false_values` | 列表 | 也将要转换为布尔 False 的值列表。 |
| `keep_default_na` | `Bool`，`default True` | 如果存在`na_values`参数，并且`keep_default_na`为`False`，则默认 NaN 值将被忽略，否则会将它们附加到 |
| `thousands` | `Str`，`default None` | 千位分隔符 |
| `nrows` | `Int`，`default None` | 限制要从文件读取的行数。 |
| `error_bad_lines` | `Boolean`，`default True` | 如果设置为 True，则即使解析期间发生错误，也将返回 DataFrame。 |

除了`read_csv()`功能外，我们在 Pandas 中还具有其他一些解析功能：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `read_table` | 将常规定界文件读入 DataFrame |
| `read_fwf` | 将固定宽度格式的行表读入 DataFrame |
| `read_clipboard` | 从剪贴板中读取文本，然后传递到`read_table`。 这对于从网页转换表很有用 |

在某些情况下，我们无法使用这些功能自动分析磁盘中的数据文件。 在这种情况下，我们也可以打开文件并通过阅读器进行迭代，这由标准库中的 CSV 模块支持：

```pypy
$ cat example_data/ex_06-03.txt
Nam     7       1       male    hcm
Mai     11      1       female  hcm
Lan     25      3       female  hn
Hung    42      3       male    tn      single
Nghia   26      3       male    dn      single
Vinh    39      3       male    vl
Hong    28      4       female  dn

>>> import csv
>>> f = open('data/ex_06-03.txt')
>>> r = csv.reader(f, delimiter='\t')
>>> for line in r:
>>>    print(line)
['Nam', '7', '1', 'male', 'hcm']
['Mai', '11', '1', 'female', 'hcm']
['Lan', '25', '3', 'female', 'hn']
['Hung', '42', '3', 'male', 'tn', 'single']
['Nghia', '26', '3', 'male', 'dn', 'single']
['Vinh', '39', '3', 'male', 'vl']
['Hong', '28', '4', 'female', 'dn']

```

## 将数据写入文本格式

我们看到了如何将文本文件中的数据加载到 Pandas 数据结构中。 现在，我们将学习如何将数据从程序的数据对象导出到文本文件。 对应于`read_csv()`功能，我们还具有 Pandas 支持的`to_csv()`功能。 让我们看下面的例子：

```pypy
>>> df_ex3.to_csv('example_data/ex_06-02.out', sep = ';')

```

结果将如下所示：

```pypy
$ cat example_data/ex_06-02.out
0;1;2;3;4
Nam;7;1;male;hcm
Mai;11;1;female;hcm
Lan;25;3;female;hn
Hung;42;3;male;tn
Nghia;26;3;male;dn
Vinh;39;3;male;vl
Hong;28;4;female;dn

```

如果要在将数据写到磁盘文件中时跳过标题行或索引列，可以为标题和索引参数设置`False`值：

```pypy
>>> import sys
>>> df_ex3.to_csv(sys.stdout, sep='\t',
 header=False, index=False)
7       1       male    hcm
11      1       female  hcm
25      3       female  hn
42      3       male    tn
26      3       male    dn
39      3       male    vl
28      4       female  dn

```

我们还可以通过在`columns`参数中指定它们来将 DataFrame 列的子集写入文件：

```pypy
>>> df_ex3.to_csv(sys.stdout, columns=[3,1,4],
 header=False, sep='\t')
Nam     male    7       hcm
Mai     female  11      hcm
Lan     female  25      hn
Hung    male    42      tn
Nghia   male    26      dn
Vinh    male    39      vl
Hong    female  28      dn

```

对于系列对象，我们可以使用相同的函数将数据写入文本文件，并且参数与之前的参数基本相同。

![Writing data to text format](img/2_6_01.jpg)

# 与二进制格式的数据进行交互

我们可以使用 pickle 模块读写 Python 对象的二进制序列化，该序列可以在标准库中找到。 如果您使用创建时间较长的对象（例如某些机器学习模型），则对象序列化会很有用。 通过腌制此类对象，可以更快地访问此模型。 它还允许您以标准化方式分发 Python 对象。

Pandas 支持开箱即用的腌制。 相关方法是`read_pickle()`和`to_pickle()`功能，可以轻松地在文件中读取和写入数据。 这些方法将以 pickle 格式将数据写入磁盘，这是一种方便的短期存储格式：

```pypy
>>> df_ex3.to_pickle('example_data/ex_06-03.out')
>>> pd.read_pickle('example_data/ex_06-03.out')
 1  2       3    4
0
Nam     7  1    male  hcm
Mai    11  1  female  hcm
Lan    25  3  female   hn
Hung   42  3    male   tn
Nghia  26  3    male   dn
Vinh   39  3    male   vl
Hong   28  4  female   dn

```

## HDF5

HDF5 不是，而是数据库，而是数据模型和文件格式。 它适合于写入一，读取多的数据集。 HDF5 文件包括两种对象：数据集，它们是类似于数组的数据集合；组是类似于文件夹的容器，用于容纳数据集和其他组。 在 Python 中，存在一些用于与 HDF5 格式进行交互的接口，例如`h5py`，它使用了熟悉的 NumPy 和 Python 构造，例如字典和 NumPy 数组语法。 使用`h5py`，我们具有 HDF5 API 的高级接口，可帮助我们入门。 但是，在本模块中，我们将为这种格式引入另一种库，称为 PyTables，该库可与 pandas 对象配合使用：

```pypy
>>> store = pd.HDFStore('hdf5_store.h5')
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
Empty

```

我们创建了一个空的 HDF5 文件，名为`hdf5_store.h5`。 现在，我们可以将数据写入文件，就像将键值对添加到`dict`一样：

```pypy
>>> store['ex3'] = df_ex3
>>> store['name'] = df_ex2[0]
>>> store['hometown'] = df_ex3[4]
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
/ex3                  frame        (shape->[7,4])
/hometown             series       (shape->[1])
/name                 series       (shape->[1])

```

可以通过指定对象密钥来检索存储在 HDF5 文件中的对象：

```pypy
>>> store['name']
0      Nam
1      Mai
2      Lan
3     Hung
4    Nghia
5     Vinh
6     Hong
Name: 0, dtype: object

```

与 HDF5 文件完成交互后，我们将其关闭以释放文件句柄：

```pypy
>>> store.close()
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
File is CLOSED

```

还有其他受支持的功能对于使用 HDF5 格式很有用。 如果您需要处理大量数据，则应更详细地研究两个库-`pytables`和`h5py`。

# 与 MongoDB 中的数据进行交互

与文本文件相比，许多应用需要更强大的存储系统，这就是为什么许多应用使用数据库来存储数据的原因。 数据库的种类很多，但有两大类：关系数据库，它支持称为 SQL 的标准声明性语言；以及所谓的 NoSQL 数据库，它们通常能够在没有预定义模式的情况下工作，并且数据实例更合适 描述为文档，而不是一行。

MongoDB 是一种 NoSQL 数据库，用于将数据存储为文档，这些文档在集合中分组在一起。 文档表示为 JSON 对象。 它可以快速，可扩展地存储数据，也可以灵活地查询数据。 要在 Python 中使用 MongoDB，我们需要导入`pymongo`包并通过传递主机名和端口来打开与数据库的连接。 我们假设我们有一个 MongoDB 实例，它在默认主机（`localhost`）和端口（`27017`）上运行：

```pypy
>>> import pymongo
>>> conn = pymongo.MongoClient(host='localhost', port=27017)

```

如果我们没有在`pymongo.MongoClient()`函数中添加任何参数，它将自动使用默认的主机和端口。

在下一步中，我们将与 MongoDB 实例内部的数据库进行交互。 我们可以列出实例中可用的所有数据库：

```pypy
>>> conn.database_names()
['local']
>>> lc = conn.local
>>> lc
Database(MongoClient('localhost', 27017), 'local')

```

前面的片段说我们的 MongoDB 实例只有一个数据库，名为“本地”。 如果我们指向的数据库和集合不存在，MongoDB 将根据需要创建它们：

```pypy
>>> db = conn.db
>>> db
Database(MongoClient('localhost', 27017), 'db')

```

每个数据库包含称为集合的文档组。 我们可以将它们理解为关系数据库中的表。 要列出数据库中所有现有的集合，我们使用`collection_names()`函数：

```pypy
>>> lc.collection_names()
['startup_log', 'system.indexes']
>>> db.collection_names()
[]

```

我们的`db`数据库尚无任何集合。 让我们创建一个名为`person`的集合，并将数据从 DataFrame 对象插入其中：

```pypy
>>> collection = db.person
>>> collection
Collection(Database(MongoClient('localhost', 27017), 'db'), 'person')
>>> # insert df_ex2 DataFrame into created collection
>>> import json
>>> records = json.load(df_ex2.T.to_json()).values()
>>> records
dict_values([{'2': 3, '3': 'male', '1': 39, '4': 'vl', '0': 'Vinh'}, {'2': 3, '3': 'male', '1': 26, '4': 'dn', '0': 'Nghia'}, {'2': 4, '3': 'female', '1': 28, '4': 'dn', '0': 'Hong'}, {'2': 3, '3': 'female', '1': 25, '4': 'hn', '0': 'Lan'}, {'2': 3, '3': 'male', '1': 42, '4': 'tn', '0': 'Hung'}, {'2': 1, '3':'male', '1': 7, '4': 'hcm', '0': 'Nam'}, {'2': 1, '3': 'female', '1': 11, '4': 'hcm', '0': 'Mai'}])
>>> collection.insert(records)
[ObjectId('557da218f21c761d7c176a40'),
 ObjectId('557da218f21c761d7c176a41'),
 ObjectId('557da218f21c761d7c176a42'),
 ObjectId('557da218f21c761d7c176a43'),
 ObjectId('557da218f21c761d7c176a44'),
 ObjectId('557da218f21c761d7c176a45'),
 ObjectId('557da218f21c761d7c176a46')]

```

在将`df_ex2`移入字典之前，会对进行转置并将其转换为 JSON 字符串。 `insert()`函数从`df_ex2`接收我们创建的字典并将其保存到集合中。

如果要列出集合中的所有数据，可以执行以下命令：

```pypy
>>> for cur in collection.find():
>>>     print(cur)
{'4': 'vl', '2': 3, '3': 'male', '1': 39, '_id': ObjectId('557da218f21c761d7c176
a40'), '0': 'Vinh'}
{'4': 'dn', '2': 3, '3': 'male', '1': 26, '_id': ObjectId('557da218f21c761d7c176
a41'), '0': 'Nghia'}
{'4': 'dn', '2': 4, '3': 'female', '1': 28, '_id': ObjectId('557da218f21c761d7c1
76a42'), '0': 'Hong'}
{'4': 'hn', '2': 3, '3': 'female', '1': 25, '_id': ObjectId('557da218f21c761d7c1
76a43'), '0': 'Lan'}
{'4': 'tn', '2': 3, '3': 'male', '1': 42, '_id': ObjectId('557da218f21c761d7c176
a44'), '0': 'Hung'}
{'4': 'hcm', '2': 1, '3': 'male', '1': 7, '_id': ObjectId('557da218f21c761d7c176
a45'), '0': 'Nam'}
{'4': 'hcm', '2': 1, '3': 'female', '1': 11, '_id': ObjectId('557da218f21c761d7c
176a46'), '0': 'Mai'}

```

如果要在某些条件下从创建的集合中查询数据，则可以使用`find()`函数并传入描述我们要检索的文档的字典。 返回的结果是`cursor`类型，它支持迭代器协议：

```pypy
>>> cur = collection.find({'3' : 'male'})
>>> type(cur)
pymongo.cursor.Cursor
>>> result = pd.DataFrame(list(cur))
>>> result
 0   1  2     3    4                       _id
0   Vinh  39  3  male   vl  557da218f21c761d7c176a40
1  Nghia  26  3  male   dn  557da218f21c761d7c176a41
2   Hung  42  3  male   tn  557da218f21c761d7c176a44
3    Nam   7  1  male  hcm  557da218f21c761d7c176a45

```

有时，我们希望删除 MongdoDB 中的数据。 我们需要做的就是将查询传递给集合上的`remove()`方法：

```pypy
>>> # before removing data
>>> pd.DataFrame(list(collection.find()))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male   tn  557da218f21c761d7c176a44
5    Nam   7  1    male  hcm  557da218f21c761d7c176a45
6    Mai  11  1  female  hcm  557da218f21c761d7c176a46

>>> # after removing records which have '2' column as 1 and '3' column as 'male'
>>> collection.remove({'2': 1, '3': 'male'})
{'n': 1, 'ok': 1}
>>> cur_all = collection.find();
>>> pd.DataFrame(list(cur_all))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male   tn  557da218f21c761d7c176a44
5    Mai  11  1  female  hcm  557da218f21c761d7c176a46

```

我们逐步学习了如何在集合中插入，查询和删除数据。 现在，我们将展示如何在 MongoDB 中更新集合中的现有数据：

```pypy
>>> doc = collection.find_one({'1' : 42})
>>> doc['4'] = 'hcm'
>>> collection.save(doc)
ObjectId('557da218f21c761d7c176a44')
>>> pd.DataFrame(list(collection.find()))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male  hcm  557da218f21c761d7c176a44
5    Mai  11  1  female  hcm  557da218f21c761d7c176a46

```

下表显示了为操作 MongoDB 中的文档提供快捷方式的方法：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"></colgroup> 
| 

更新方式

 | 

描述

 |
| --- | --- |
| `inc()` | 递增数字字段 |
| `set()` | 将某些字段设置为新值 |
| `unset()` | 从文档中删除字段 |
| `push()` | 将值附加到文档中的数组 |
| `pushAll()` | 将多个值附加到文档中的数组 |
| `addToSet()` | 仅在数组中不存在的情况下添加一个值 |
| `pop()` | 删除数组的最后一个值 |
| `pull()` | 从数组中删除所有出现的值 |
| `pullAll()` | 从数组中删除所有出现的任何一组值 |
| `rename()` | 重命名字段 |
| `bit()` | 通过按位运算更新值 |

# 与 Redis 中的数据进行交互

Redis 是一种高级键值存储，其中的值可以具有不同的类型：字符串，列表，集合，排序集合或哈希。 Redis 像 memcached 一样将数据存储在内存中，但是与 memcached 不同，Redis 没有这样的选择，它可以保留在磁盘上。 Redis 支持每秒约 100,000 次 set 或 get 操作的快速读写。

要与 Redis 交互，我们需要将`Redis-py`模块安装到 Python，该模块在`pypi`上可用，并且可以与`pip`一起安装：

```pypy
$ pip install redis

```

现在，我们可以通过数据库服务器的主机和端口连接到 Redis。 我们假设我们已经安装了 Redis 服务器，该服务器正在使用默认主机（`localhost`）和端口（`6379`）参数运行：

```pypy
>>> import redis
>>> r = redis.StrictRedis(host='127.0.0.1', port=6379)
>>> r
StrictRedis<ConnectionPool<Connection<host=localhost,port=6379,db=0>>>

```

作为在 Redis 中存储数据的第一步，我们需要定义哪种数据结构适合我们的需求。 在本节中，我们将介绍 Redis 中的四种常用数据结构：简单值，列表，集合和有序集合。 尽管数据以许多不同的数据结构存储到 Redis 中，但是每个值都必须与一个键相关联。

## 简单值

这是 Redis 中最基本的一种价值。 对于 Redis 中的每个键，我们还有一个可以具有数据类型的值，例如字符串，整数或双精度型。 让我们以一个示例为例，该示例用于在 Redis 中设置数据和从 Redis 中获取数据：

```pypy
>>> r.set('gender:An', 'male')
True
>>> r.get('gender:An')
b'male'

```

在此示例中，我们要将名为`An`的人的性别信息存储到 Redis 中。 我们的密钥是`gender:An`，我们的值是`male`。 它们都是字符串类型。

`set()`功能接收两个参数：键和值。 第一个参数是键，第二个参数是值。 如果要更新此键的值，则只需再次调用该函数并更改第二个参数的值即可。 Redis 会自动更新它。

`get()`函数将检索我们的键的值，该值作为参数传递。 在这种情况下，我们想要获取密钥`gender:An`的性别信息。

在第二个示例中，我们向您显示另一种值类型，即整数：

```pypy
>>> r.set('visited_time:An', 12)
True
>>> r.get('visited_time:An')
b'12'
>>> r.incr('visited_time:An', 1)
13
>>> r.get('visited_time:An')
b'13'

```

我们看到了一个新函数`incr()`，该函数用于将 key 的值增加给定的数量。 如果我们的密钥不存在，则 RedisDB 将使用给定的增量作为值来创建密钥。

![The simple value](img/2_6_02.jpg)

## 列表

我们有几种方法与 Redis 中的列表值进行交互。 下面的示例使用`rpush()`和`lrange()`函数将列表数据放置到 DB 中以及从 DB 中获取列表数据：

```pypy
>>> r.rpush('name_list', 'Tom')
1L
>>> r.rpush('name_list', 'John')
2L
>>> r.rpush('name_list', 'Mary')
3L
>>> r.rpush('name_list', 'Jan')
4L
>>> r.lrange('name_list', 0, -1)
[b'Tom', b'John', b'Mary', b'Jan']
>>> r.llen('name_list')
4
>>> r.lindex('name_list', 1)
b'John'

```

除了在示例中使用的`rpush()`和`lrange()`函数之外，我们还想介绍另外两个函数。 首先，`llen()`函数用于获取给定密钥在 Redis 中列表的长度。 `lindex()`功能是检索列表项的另一种方法。 我们需要将两个参数传递给函数：列表中的键和项的索引。 下表列出了使用 Redis 处理列表数据结构时的其他一些强大功能：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `rpushx(name, value)` | 如果名称存在，则将值推到列表名称的末尾 |
| `rpop(name)` | 删除并返回列表名称的最后一项 |
| `lset(name, index, value)` | 将列表名称的索引位置处的项目设置为输入值 |
| `lpushx(name,value)` | 如果名称存在，则将值推入列表名称的开头 |
| `lpop(name)` | 删除并返回列表名称的第一项 |

## 设置

此数据结构也类似于列表类型。 但是，与列表相反，我们不能在集合中存储重复值：

```pypy
>>> r.sadd('country', 'USA')
1
>>> r.sadd('country', 'Italy')
1
>>> r.sadd('country', 'Singapore')
1
>>> r.sadd('country', 'Singapore')
0
>>> r.smembers('country')
{b'Italy', b'Singapore', b'USA'}
>>> r.srem('country', 'Singapore')
1
>>> r.smembers('country')
{b'Italy', b'USA'}

```

与与列表数据结构相对应，我们还具有许多功能来获取，设置，更新或删除集合中的项目。 下表列出了支持的用于数据结构的函数：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `sadd(name, values)` | 使用键名将值添加到集合中 |
| `scard(name)` | 用键名返回集合中的元素数 |
| `smembers(name)` | 返回键名称为 set 的所有成员 |
| `srem(name, values)` | 从键名称集中删除值 |

## 有序集

当我们将数据添加到称为**得分**的集合中时，有序集合数据结构具有额外的属性。 有序集合将使用分数来确定集合中元素的顺序：

```pypy
>>> r.zadd('person:A', 10, 'sub:Math')
1
>>> r.zadd('person:A', 7, 'sub:Bio')
1
>>> r.zadd('person:A', 8, 'sub:Chem')
1
>>> r.zrange('person:A', 0, -1)
[b'sub:Bio', b'sub:Chem', b'sub:Math']
>>> r.zrange('person:A', 0, -1, withscores=True)
[(b'sub:Bio', 7.0), (b'sub:Chem', 8.0), (b'sub:Math', 10.0)]

```

通过使用`zrange(name, start, end)`函数，我们可以从开始和结束得分之间的排序集中获得一系列值（默认情况下，这些得分以升序排序）。 如果要更改`way`的排序方法，可以将`desc`参数设置为`True`。 如果要获取分数和返回值，请使用`withscore`参数。 返回类型是（值，得分）对的列表，如您在前面的示例中看到的那样。

请参阅下表以了解有序集合上可用的更多功能：

<colgroup class="calibre17"><col class="calibre18"> <col class="calibre18"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `zcard(name)` | 返回具有键名称的排序集中的元素数 |
| `zincrby(name, value, amount=1)` | 将键名与排序集中的值的分数按数量递增 |
| `zrangebyscore(name, min, max, withscores=False, start=None, num=None)` | 从具有键名的排序集中返回一个范围在最小和最大之间的值。如果`withscores`为`true`，则返回分数和值。如果给定 start 和`num`，则返回范围的一部分 |
| `zrank(name, value)` | 返回从 0 开始的值，该值指示键名在排序集中的值的排名 |
| `zrem(name, values)` | 从具有键名的排序集中删除成员值 |

![Ordered set](img/2_6_03.jpg)

![Ordered set](img/C_02_06.jpg)

![Ordered set](img/Summary_02_06.jpg)

![Ordered set](img/Yourprogress_02.jpg)