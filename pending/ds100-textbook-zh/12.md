# 概率与泛化

> 原文：[https://www.bookbookmark.ds100.org/ch/12/prob_and_gen.html](https://www.bookbookmark.ds100.org/ch/12/prob_and_gen.html)

```
# HIDDEN
# Clear previously defined variables
%reset -f

# Set directory for data loading to work properly
import os
os.chdir(os.path.expanduser('~/notebooks/12'))

```

我们介绍了一系列使用数据集创建模型的步骤：

1.  选择一个模型。
2.  选择损失函数。
3.  通过最小化数据集上的损失来适应模型。

到目前为止，我们引入了常数模型（1）、一组损失函数（2）和梯度下降作为最小化损失（3）的一般方法。遵循这些步骤通常会生成一个模型，对它所训练的数据集进行精确预测。

不幸的是，一个只在训练数据上表现良好的模型几乎没有实际的实用性。我们关心模型对**归纳**的能力。我们的模型应该对人口做出准确的预测，而不仅仅是训练数据。这个问题似乎很难回答我们如何解释尚未看到的数据？

这里我们来看看统计的推论能力。我们首先介绍一些数学工具：随机变量、期望和方差。使用这些工具，我们可以根据我们的人口数据，甚至是我们没有用来训练模型的数据，得出关于模型长期性能的结论！

## 12.1 随机变量

```
# HIDDEN
# Clear previously defined variables
%reset -f

# Set directory for data loading to work properly
import os
os.chdir(os.path.expanduser('~/notebooks/12'))

```

```
# HIDDEN
import warnings
# Ignore numpy dtype warnings. These warnings are caused by an interaction
# between numpy and Cython and can be safely ignored.
# Reference: https://stackoverflow.com/a/40846742
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
%matplotlib inline
import ipywidgets as widgets
from ipywidgets import interact, interactive, fixed, interact_manual
import nbinteract as nbi

sns.set()
sns.set_context('talk')
np.set_printoptions(threshold=20, precision=2, suppress=True)
pd.options.display.max_rows = 7
pd.options.display.max_columns = 8
pd.set_option('precision', 2)
# This option stops scientific notation for pandas
# pd.set_option('display.float_format', '{:.2f}'.format)

```

```
# HIDDEN
import scipy.stats as stats

```

几乎所有现实世界中的现象都包含一定程度的随机性，使得数据生成和收集本身就是随机过程。由于我们将模型与这些数据相匹配，因此我们的模型也包含随机性。为了数学上表示这些随机过程，我们使用随机变量。

**随机变量**是一个代数变量，表示由概率事件确定的**数值。在本书中，我们总是使用大写字母（不是希腊字母），如$X$或$Y$来表示随机变量。尽管随机变量可以代表离散的（如 10 人样本中男性的数量）或连续的数量（如洛杉矶的平均温度），但我们将仅在本教材中使用离散随机变量。**

我们必须总是指定一个给定的随机变量代表什么。例如，我们可以写下随机变量$x$表示 10 个硬币翻转中的头数。随机变量的定义决定了它可以接受的值。在本例中，$x$只能包含 0$到 10$之间的值。

我们还必须能够确定随机变量接受每个可能值的概率。例如，$x=0$被写为$p（x=0）=（0.5）^ 10$的概率，我们同样可以计算$x$是任何以$0，1，ldots，10 为单位的值的概率。

### 概率质量函数

随机变量$x$的**概率质量函数（pmf）**或**分布**提供$x$接受其每个可能值的概率。如果我们将$\mathbb x 设为$x$可以接受的一组值，并且$x$是$\mathbb x 中的特定值，则$x$的 PMF 必须满足以下规则：

$$ 1) \sum_{x \in \mathbb{X}} P(X = x) = 1 $$$$ 2) \text{ For all } x \in \mathbb{X}, 0 \leq P(X = x) \leq 1 $$

第一条规则规定，$x$sum 到$1$的所有可能值的概率。

第二条规则规定，给定值$x$的每个概率必须介于$0$和$1$之间。

假设我们让 x 美元代表一个公平的六面骰子的一个骰子的结果。我们知道，$x 在 1、2、3、4、5、6 中，$p（x=1）=p（x=2）=\ldots=p（x=6）=\frac 1 6 美元。我们可以绘制$x$的 PMF 作为概率分布：

```
# HIDDEN

def plot_pmf(xs, probs, rv_name='X'):
    plt.plot(xs, probs, 'ro', ms=12, mec='b', color='b')
    plt.vlines(xs, 0, probs, colors='b', lw=4)
    plt.xlabel('$x$')
    plt.ylabel('$P(X = x)$')
    plt.ylim(0, 1)
    plt.title('PMF of $X$');

```

```
# HIDDEN
xk = np.arange(1, 7)
pk = (1/6, 1/6, 1/6, 1/6, 1/6, 1/6)

plot_pmf(np.arange(1, 7), np.repeat(1/6, 6))

plt.yticks(np.linspace(0, 1, 7),
           ('0', r'$\frac{1}{6}$', r'$\frac{2}{6}$', r'$\frac{3}{6}$',
            r'$\frac{4}{6}$', r'$\frac{5}{6}$', '1'));

```

![](img/ab3ba858f64515b244aaf4c65f86665b.jpg)

### 关节分布

单随机变量的 PMF 概念自然地扩展到多随机变量的联合分布。特别是，两个或多个随机变量的**联合分布**产生这些随机变量同时接受一组特定值的概率。

例如，让随机变量$X$表示 10 个硬币翻转中的头数，让$Y$表示同一组 10 个硬币翻转中的尾部数。我们可以注意到：

$$P(X=0, Y=10) = P(X=10, Y=0) = (0.5)^{10}$$

同时$P（x=6，y=6）=0 美元，因为我们不可能在 10 个硬币翻转中有 6 个头部和 6 个尾部。

#### 边际分布

有时，我们从两个随机变量$X$和$Y$的联合分布开始，但只想找到$X$的分布。这个分布称为**边际分布**。为了找出$x$接受某个特定值的概率，我们必须考虑所有可能的$y$值（用$\mathbb y 表示），这些值可以与$x$同时发生，并对所有这些联合概率求和：

$$ \begin{aligned} \sum_{y \in \mathbb{Y}} P(X=x, Y=y) &= P(X=x) \end{aligned} $$

我们可以证明如下身份：

$$ \begin{aligned} \sum_{y \in \mathbb{Y}} P(X=x, Y=y) &= \sum_{y \in \mathbb{Y}} P(X=x) \times P(Y=y \; \vert \; X=x)\\ &= P(X=x) \times \sum_{y \in \mathbb{Y}} P(Y=y \; \vert \; X=x)\\ &= P(X=x) \times 1 \\ &= P(X=x) \end{aligned} $$

在这个证明的最后一行中，我们将$y\；\vert\；x=x$作为一个带有未知 pmf 的随机变量。这一点很重要，因为我们使用了一个属性，即 pmf 中的概率总和为 1 美元，这意味着在 mathbb y p（y=y \ vert \ x=x）=1 美元。

#### 独立随机变量

像事件一样，两个随机变量可以是相依的或独立的。任何两个随机变量都是独立的，只要知道一个变量的结果不会改变观察另一个变量任何结果的概率。

例如，假设我们把一枚硬币掷十次，让$x$作为头的数目，让$y$作为尾的数目。显然，$x$和$y$是因变量，因为知道$x=0$意味着$y$必须等于$10$。如果我们没有观察到$X$的值，$Y$可以以非零概率在$0$和$10$之间取任何值。

我们可以做两组十次翻转。如果$x$是第一组翻转中的头数，$y$是第二组翻转中的头数，$x$和$y$是独立的，因为第一组十个翻转的结果不会影响第二组翻转的结果。

### 年龄[¶](#An-Example-with-Ages)的例子

假设我们有一个由四个人组成的小数据集：

```
# HIDDEN
data={"Name":["Carol","Bob","John","Dave"], 'Age': [50,52,51,50]}
people = pd.DataFrame(data)
people

```

|  | 姓名 | 年龄 |
| --- | --- | --- |
| 零 | 颂歌 | 五十 |
| --- | --- | --- |
| 1 个 | 鲍勃 | 五十二 |
| --- | --- | --- |
| 二 | 约翰 | 五十一 |
| --- | --- | --- |
| 三 | 戴夫 | 50 |
| --- | --- | --- |

假设我们从这个数据集中抽取两个人进行替换。如果随机变量$Z$代表样本中第一和第二个人的年龄差异，那么$Z$的 PMF 是什么？

为了解决这个问题，我们定义了两个新的随机变量。我们将$X$定义为第一个人的年龄，$Y$定义为第二个人的年龄。那么，$Z=X-Y$就可以了。然后，我们找到 x$和 y$的联合概率分布：x$和 y$可以同时接受的每个值的概率。在这种情况下，请注意$x$和$y$是独立的，分布相同；这两个随机变量表示来自同一数据集的两个独立的提取，第一个提取对第二个提取没有影响。例如，$x=51$和$y=50$的概率是$p（x=51，y=50）=\frac 1 4 \cdot\frac 2 4 frac 2 16。以类似的方式，我们得到：

|  | Y＝50 美元 | Y＝51 美元 | Y＝52 美元 |
| --- | --- | --- | --- |
| X＝50 美元 | 4/16 | 2/16 | 2/16 |
| X＝51 美元 | 2/16 | 1/16 | 1/16 |
| X＝52 美元 | 2/16 | 1/16 | 1/16 |

现在让我们考虑一下这样的情况：我们从上面相同的数据集中抽取两个人，但没有替换。如前所述，我们将$X$定义为第一个人的年龄，$Y$定义为第二个人的年龄，$Z=X-Y$。但是，现在$X$和$Y$不是独立的；例如，如果我们知道$X=51$，那么$Y\neq 51$。我们发现 X 美元和 Y 美元的联合分配如下：

|  | $Y=50$ | $Y=51$ | $Y=52$ |
| --- | --- | --- | --- |
| $X=50$ | 2/12 | 2/12 | 2/12 |
| $X=51$ | 2/12 | 零 | 1/12 |
| $X=52$ | 2/12 | 1/12 | 0 |

我们还可以从表中找到$Y$的边际分布。

$$ \begin{aligned} P(Y = 50) &= P(Y = 50, X = 50) + P(Y = 50, X = 51) + P(Y = 50, X = 52) \\ &= \frac{2}{12} + \frac{2}{12} + \frac{2}{12} \\ &= \frac{1}{2} \\ P(Y = 51) &= \frac{2}{12} + 0 + \frac{1}{12} = \frac{1}{4} \\ P(Y = 52) &= \frac{2}{12} + \frac{1}{12} + 0 = \frac{1}{4} \end{aligned} $$

注意，我们对上面的联合分布表的每一列进行了汇总。我们可以想象计算每一列的总和，并将结果写在下表的空白处；这是术语边际分布的起源。

您还应该注意到，$X$和$Y$在没有替换的情况下采样时是不独立的。例如，如果 x=52 美元，$y\neq 52 美元。然而，$x$和$y$的边际分布仍然相同。

## 摘要[¶](#Summary)

在本节中，我们将介绍随机变量，即根据随机过程获取值的数学变量。这些结果必须完全准确地定义，每个结果都必须有明确的发生概率。随机变量可以用来表示许多随机现象，包括数据收集过程。

## 12.2 期望和方差

```
# HIDDEN
# Clear previously defined variables
%reset -f

# Set directory for data loading to work properly
import os
os.chdir(os.path.expanduser('~/notebooks/12'))

```

```
# HIDDEN
import warnings
# Ignore numpy dtype warnings. These warnings are caused by an interaction
# between numpy and Cython and can be safely ignored.
# Reference: https://stackoverflow.com/a/40846742
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
%matplotlib inline
import ipywidgets as widgets
from ipywidgets import interact, interactive, fixed, interact_manual
import nbinteract as nbi

sns.set()
sns.set_context('talk')
np.set_printoptions(threshold=20, precision=2, suppress=True)
pd.options.display.max_rows = 7
pd.options.display.max_columns = 8
pd.set_option('precision', 2)
# This option stops scientific notation for pandas
# pd.set_option('display.float_format', '{:.2f}'.format)

```

虽然随机变量完全由其概率质量函数（PMF）描述，但我们经常使用**期望**和**方差**来描述变量的长期平均值和分布。这两个值具有独特的数学性质，对数据科学具有特别重要的意义，例如，我们可以通过显示其预期值等于总体参数来证明长期的估计是准确的。我们通过定义期望值和方差，介绍它们最有用的数学性质，并用一个简单的估计应用来结束。

### 期望值[¶](#Expectation)

我们经常对随机变量的长期平均值感兴趣，因为它给我们一个变量分布中心的感觉。我们将这种长期平均值称为随机变量的**期望值**或**期望值**。随机变量$x$的预期值为：

$$\mathbb{E}[X] = \sum_{x\in \mathbb{X}} x \cdot P(X = x)$$

例如，如果$x$表示一个公平的六面骰子的滚动，

$$ \begin{aligned} \mathbb{E}[X] &= 1 \cdot P(X = 1) + 2 \cdot P(X = 2) + \ldots + 6 \cdot P(X = 6) \\ &= 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \ldots + 6 \cdot \frac{1}{6} \\ &= 3.5 \end{aligned} $$

注意$x$的预期值不一定是$x$的可能值。虽然$\mathbb e[x]=3.5$，但$x$实际上不能接受$3.5$的值。

**示例：**从上一节调用数据集：

```
# HIDDEN
data={"Name":["Carol","Bob","John","Dave"], 'Age': [50,52,51,50]}
people = pd.DataFrame(data)
people

```

|  | 姓名 | 年龄 |
| --- | --- | --- |
| 零 | 颂歌 | 五十 |
| --- | --- | --- |
| 1 个 | 鲍勃 | 五十二 |
| --- | --- | --- |
| 二 | 约翰 | 五十一 |
| --- | --- | --- |
| 三 | 戴夫 | 50 |
| --- | --- | --- |

我们从这个数据集中随机选择一个人。假设$Y$是表示此人年龄的随机变量。然后：

$$ \begin{aligned} \mathbb{E}[Y] &= 50 \cdot P(Y = 50) + 51 \cdot P(Y = 51) + 52 \cdot P(Y = 52) \\ &= 50 \cdot \frac{2}{4} + 51 \cdot \frac{1}{4} + 52 \cdot \frac{1}{4} \\ &= 50.75 \end{aligned} $$

**示例：**假设我们从数据集中抽取两个人进行替换。如果随机变量$Z$表示样本中第一和第二个人的年龄差，那么什么是$\mathbb e[Z]$？

如前一节所述，我们将$X$定义为第一个人的年龄，将$Y$定义为第二个人的年龄，这样$Z=X-Y$。从上一节给出的 x 美元和 y 美元的联合分配中，我们可以找到 z 美元的 PMF。例如，$P（Z=1）=P（X=51，Y=50）+P（X=52，Y=51）=\frac 3 16$。因此，

$$ \begin{aligned} \mathbb{E}[Z] &= (-2) \cdot P(Z = -2) + (-1) \cdot P(Z = -1) + \ldots + (2) \cdot P(Z = 2) \\ &= (-2) \cdot \frac{2}{16} + (-1) \cdot \frac{3}{16}+ \ldots + (2) \cdot \frac{2}{16} \\ &= 0 \end{aligned} $$

由于$\mathbb e[z]=0$，我们预计从长远来看，2 号样本中的人的年龄差异将为 0。

#### 期望线性度

当我们像上面所做的那样处理随机变量的线性组合时，我们通常可以很好地利用期望**的线性**，而不是单调地单独计算每个联合概率。

期望的线性表示：

$$ \begin{aligned} \mathbb{E}[X + Y] &= \mathbb{E}[X] + \mathbb{E}[Y] \\ \end{aligned} $$

根据这一说法，我们还可以得出：

$$ \begin{aligned} \mathbb{E}[cX] &= c\mathbb{E}[X] \\ \end{aligned} $$

其中$x$和$y$是随机变量，而$c$是常量。

换句话说，任意两个随机变量之和的期望值等于这些变量的期望值之和。

在上一个示例中，我们看到$Z=X-Y$。因此，$\mathbb e[z]=\mathbb[x-y]=\mathbb[x]-\mathbb[y]$。

现在我们可以分别计算$\mathbb e[x]$和$\mathbb e[y]$了。因为$\mathbb e[x]=\mathbb e[y]=50.75$，$\mathbb e[z]=50.75-50.75=0$。

即使 X 美元和 Y 美元相互依赖，期望的线性关系仍然存在！作为一个例子，让我们再次考虑一下这样一种情况：我们从前面部分的小数据集中抽取两个人进行样本，而不进行替换。如前所述，我们将$X$定义为第一个人的年龄，$Y$定义为第二个人的年龄，$Z=X-Y$。很明显，$X$和$Y$不是独立的，例如，知道$X=52$就意味着$Y\neq 52$。

从上一节给出的$x$和$y$的联合分配中，我们可以找到$\mathbb e[z]$：

$$ \begin{aligned} \mathbb{E}[Z] &= (-2) \cdot P(Z = -2) + (-1) \cdot P(Z = -1) + \ldots + (2) \cdot P(Z = 2) \\ &= (-2) \cdot \frac{2}{12} + (-1) \cdot \frac{3}{12}+ \ldots + (2) \cdot \frac{2}{12} \\ &= 0 \end{aligned} $$

计算这个期望的一个简单方法是使用期望的线性。即使$X$和$Y$依赖，$\MathBB E[Z]=\MathBB E[X-Y]=\MathBB[X]-\MathBB[Y]$。回想上一节，$x$和$y$具有相同的 pmf，即使我们在不替换的情况下采样，这意味着$\mathbb e[x]=\mathbb[y]=50.75$。因此，与第一个场景一样，$\mathbb e[z]=0$。

注意期望的线性仅适用于随机变量的线性组合。例如，$\mathbb e[x y]=\mathbb[x]\mathbb[y]$不是$x$和$y$的线性组合。在这种情况下，$\mathbb e[x y]=\mathbb[x]\mathbb[y]$通常仅适用于独立随机变量。

### 方差[¶](#Variance)

随机变量的方差是变量排列的数值描述。对于随机变量$X$：

$$ \begin{aligned} Var(X) &= \mathbb{E}[(X - \mathbb{E}[X])^2] \\ \end{aligned} $$

上述公式表明，x$的方差是 x$预期值的平均平方距离。

对于我们为了简洁而省略的一些代数操作，我们也可以等效地写：

$$ \begin{aligned} Var(X) &= \mathbb{E}[X^2] - \mathbb{E}[X]^2 \\ \end{aligned} $$

考虑以下两个随机变量$X$和$Y$的概率分布：

```
# HIDDEN

def plot_pmf(xs, probs, rv_name='X', val_name='x', prob_denom=4):
    plt.plot(xs, probs, 'ro', ms=12, mec='b', color='b')
    plt.vlines(xs, 0, probs, colors='b', lw=4)
    plt.xlabel(f'${val_name}$')
    plt.ylabel(f'$P({rv_name} = {val_name})$')
    plt.ylim(0, 1)
    plt.yticks(np.linspace(0, 1, prob_denom + 1),
               ['0']
               + [rf'$\frac{{{n}}}{{{prob_denom}}}$'
                  for n in range(1, prob_denom)]
               + ['1'])
    plt.title(f'PMF of ${rv_name}$');

```

```
# HIDDEN

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plot_pmf([-1, 1], [0.5, 0.5])
plt.xlim(-2, 2);

plt.subplot(1, 2, 2)
plot_pmf((-2, -1, 1, 2), (1/4, 1/4, 1/4, 1/4), rv_name='Y', val_name='y')
plt.tight_layout()

```

![](img/c38dbc9449b87fc58a45cc3ddf8829df.jpg)

$x$的值为-1 和 1，概率分别为\frac 1 2。$Y$的值为-2、-1、1 和 2，概率分别为\frac 1 4。我们发现$\mathbb e[x]=\mathbb e[y]=0$。由于$Y$的分布比$X$的分布更高，我们预计$var（y）$大于$var（x）$。

$$ \begin{aligned} Var(X) &= \mathbb{E}[X^2] - \mathbb{E}[X]^2 \\ &= \mathbb{E}[X^2] - 0^2 \\ &= \mathbb{E}[X^2] \\ &= (-1)^2 P(X = -1) + (1)^2 P(X = 1) \\ &= 1 \cdot 0.5 + 1 \cdot 0.5 \\ &= 1 \\\\ Var(Y) &= \mathbb{E}[Y^2] - \mathbb{E}[Y]^2 \\ &= \mathbb{E}[Y^2] - 0^2 \\ &= \mathbb{E}[Y^2] \\ &= (-2)^2 P(Y = -2) + (-1)^2 P(Y = -1) + (1)^2 P(Y = 1) + (2)^2 P(Y = 2) \\ &= 4 \cdot 0.25 + 1 \cdot 0.25 + 1 \cdot 0.25 + 4 \cdot 0.25\\ &= 2.5 \end{aligned} $$

如预期的那样，$Y$的差异大于$X$的差异。

方差有一个有用的特性来简化一些计算。如果$x$是随机变量：

$$ \begin{aligned} Var(aX + b) &= a^2 Var(X) \end{aligned} $$

如果两个随机变量$x$和$y$是独立的：

$$ \begin{aligned} Var(X + Y) = Var(X) + Var(Y) \end{aligned} $$

请注意，期望的线性度适用于任何 x 美元和 y 美元，即使它们是相互依赖的。然而，$var（x+y）=var（x）+var（y）$只有当$x$和$y$独立于**时才持有。**

#### 协方差

两个随机变量$x$和$y$的协方差定义为：

$$ \begin{aligned} Cov(X, Y) &= \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] \end{aligned} $$

同样，我们可以执行一些代数操作来获得：

$$ \begin{aligned} Cov(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] \end{aligned} $$

注意，虽然一个随机变量的方差必须是非负的，但是两个随机变量的协方差可以是负的。事实上，协方差有助于测量两个随机变量之间的相关性；协方差的符号有助于我们确定两个随机变量是正相关还是负相关。如果两个随机变量$x$和$y$是独立的，那么$cov（x，y）=0$和$\mathbb[xy]=\mathbb[x]\mathbb[y]$。

### 伯努利随机变量

假设我们想使用一个随机变量$x$来模拟一个带有$p（头）=p$的有偏硬币。我们可以说，如果硬币是正面的，x=1 美元；如果硬币是反面的，x=0 美元。因此，$P（x=1）=P$和$P（x=0）=1-P$之间。这种二元随机变量称为伯努利随机变量，我们可以计算其期望值和方差如下：

$$\mathbb{E}[X] = 1 \times p + 0 \times (1 - p) = p$$$$ \begin{aligned} Var(X) &= \mathbb{E}[X^2] - \mathbb{E}[X]^2 \\ &= 1^2 \times p + 0^2 \times (1 - p) - p^2 \\ &= p - p^2 \\ &= p(1 - p) \end{aligned} $$

### 样本是指[¶](#Sample-Means)

假设我们拥有一个有偏见的硬币，它的面值为$P（头）=P$并且我们想估计$P$的价值。我们可以将硬币翻转$n$次，以收集翻转样本，并计算样本中头部的比例，$\hat p$。如果我们知道$\hat p$经常接近$p$，我们可以将$\hat p$用作$p$的**估计量**。

注意$P$是 _ 而不是 _ 一个随机的数量；它是一个基于硬币偏差的固定值。然而，$\hat p$是一个随机量，因为它是由抛硬币的随机结果产生的。因此，我们可以计算期望值和方差，以精确地理解它对$P$的估计。

要计算$\mathbb e[\hat p]$，我们将首先为示例中的每个翻转定义随机变量。让$x_i$成为$i_th$coin flip 的伯努利随机变量。那么，我们知道：

$$ \begin{aligned} \hat p = \frac{X_1 + X_2 + \ldots + X_n}{n} \end{aligned} $$

为了计算期望值为$\hat p$，我们可以插入上面的公式，并使用这样一个事实，$\mathbb e[x_i]=p$，因为$x_i$是伯努利随机变量。

$$ \begin{aligned} \mathbb{E}[\hat p] &= \mathbb{E} \left[ \frac{X_1 + X_2 + \ldots + X_n}{n} \right] \\ &= \frac{1}{n} \mathbb{E}[X_1 + \ldots + X_n] \\ &= \frac{1}{n} \left( \mathbb{E}[X_1] + \ldots + \mathbb{E}[X_n] \right) \\ &= \frac{1}{n} (p + \ldots + p) \\ &= \frac{1}{n} (np) \\ \mathbb{E}[\hat p] &= p \end{aligned} $$

我们发现$\mathbb e[\hat p]=p$。换句话说，有了足够的翻转，我们预计我们的估值器$\hat p$将收敛到真正的硬币偏差$p$。我们说，P$是一个$P$的**无偏估计量**。

接下来，我们计算出 p$的方差。因为每个翻转都独立于其他翻转，我们知道$x_i$是独立的。这允许我们使用方差的线性。

$$ \begin{aligned} Var(\hat p) &= Var \left(\frac{1}{n} \sum_{i=1}^{n} X_i \right) \\ &= \frac{1}{n^2} \sum_{i=1}^{n}Var(X_i) \\ &= \frac{1}{n^2} \times np(1-p) \\ Var(\hat p) &= \frac{p(1-p)}{n} \end{aligned} $$

从上面的等价性可以看出，随着样本中翻转次数的增加，估计量的方差会减少。换句话说，如果我们收集了大量的数据，我们可以更确定我们的估计值。这种行为被称为大数定律。

## 摘要[¶](#Summary)

我们使用期望和方差来简单描述随机变量的中心和分布。这些数学工具使我们能够确定从一个样本计算出的一个数量如何估计人口中的一个数量。

最小化损失函数将创建一个对其训练数据精确的模型。期望值和方差允许我们对模型对来自人群的未知数据的准确性做出一般性的陈述。

## 12.3 风险

```
# HIDDEN
# Clear previously defined variables
%reset -f

# Set directory for data loading to work properly
import os
os.chdir(os.path.expanduser('~/notebooks/12'))

```

在上一章介绍的建模场景中，服务生收集了特定月份工作的提示数据集。我们选择了一个常数模型，并最小化了该数据集上的均方误差（mse）损失函数，确保我们的常数模型在该数据集和损失函数上优于所有其他常数模型。常量模型只有一个参数，$\theta$。我们发现优化参数$\hat \theta=\text mean（\textbf y）$用于 MSE 损失。

虽然这样的模型对训练数据做出了相对准确的预测，但我们想知道这个模型在来自人群的新数据上是否会表现良好。为了表示这个概念，我们引入了统计**风险**，也称为**预期损失**。

### 定义[¶](#Definition)

模型的风险是从人群中随机选择的点上模型损失的预期值。

在这种情况下，总人数包括我们的服务员在工作期间收到的所有小费百分比，包括未来的小费。我们使用随机变量$x$表示从总体中随机选择的提示百分比，而通常变量$theta$表示常量模型的预测。使用这个符号，我们模型的风险$r（\theta）$是：

$$ \begin{aligned} R(\theta) = \mathbb{E}\left[(X - \theta)^2\right] \end{aligned} $$

在上面的表达式中，我们使用 MSE 损失，它给出期望值中的内部$（x-\theta）^2$。风险是$\theta$的函数，因为我们可以根据需要更改$\theta$。

与单纯的损失不同，使用风险可以让我们推断模型对总体人口的准确性。如果我们的模型达到一个低风险，我们的模型将作出准确的预测点从人口长期。另一方面，如果我们的模型具有很高的风险，那么一般来说，它在来自人群的数据上表现不佳。

当然，我们希望选择能使模型的风险尽可能低的$theta$值。我们使用变量$\theta^*$来表示风险最小化值$\theta$或人口的最佳模型参数。为了澄清，$\theta^*$表示风险最小化的模型参数，而$\hat \theta$表示数据集特定损失最小化的参数。

### 最小化风险

让我们找一个能将风险降到最低的价值为\theta$以前，我们用微积分来实现这个最小化。这一次，我们将使用一个产生有意义的最终表达式的数学技巧。我们将$x-\theta$替换为$x-\mathbb e[x]+\mathbb e[x]-\theta$并展开：

$$ \begin{aligned} R(\theta) &= \mathbb{E}[(X - \theta)^2] \\ &= \mathbb{E}\left[ (X - \mathbb{E}[X] + \mathbb{E}[X] - \theta)^2 \right] \\ &= \mathbb{E}\left[ \bigl( (X - \mathbb{E}[X]) + (\mathbb{E}[X] - \theta) \bigr)^2 \right] \\ &= \mathbb{E}\left[ (X - \mathbb{E}[X])^2 + 2(X - \mathbb{E}[X])(\mathbb{E}[X] - \theta) + (\mathbb{E}[X]- \theta)^2 \right] \\ \end{aligned} $$

现在，我们应用期望的线性并简化。我们使用标识$\mathbb e \ left[（x-\mathbb e[x]）\right]=0$这大致相当于说明$\mathbb e[x]位于$x$的分布中心。

$$ \begin{aligned} R(\theta) &= \mathbb{E}\left[ (X - \mathbb{E}[X])^2 \right] + \mathbb{E}\left[ 2(X - \mathbb{E}[X])(\mathbb{E}[X] - \theta) \right] + \mathbb{E}\left[ (\mathbb{E}[X]- \theta)^2 \right] \\ &= \mathbb{E}\left[ (X - \mathbb{E}[X])^2 \right] + 2 (\mathbb{E}[X] - \theta) \underbrace{ \mathbb{E}\left[ (X - \mathbb{E}[X]) \right]}_{= 0} + (\mathbb{E}[X]- \theta)^2 \\ &= \mathbb{E}\left[ (X - \mathbb{E}[X])^2 \right] + 0 + (\mathbb{E}[X]- \theta)^2 \\ R(\theta) &= \mathbb{E}\left[ (X - \mathbb{E}[X])^2 \right] + (\mathbb{E}[X]- \theta)^2 \\ \end{aligned} $$

注意，上面表达式中的第一个术语是$x$，$var（x）$的**方差**，它不依赖于$\theta$。第二个术语给出了$\theta$与$\mathbb e[x]$的接近程度。因此，第二个术语被称为我们模型的**偏差**。换句话说，模型的风险是模型的偏差加上我们试图预测的数量的方差：

$$ \begin{aligned} R(\theta) &= \underbrace{(\mathbb{E}[X]- \theta)^2}_\text{bias} + \underbrace{Var(X)}_\text{variance} \end{aligned} $$

因此，当我们的模型没有偏差时，风险最小化：$\theta^*=\mathbb e[x]$。

#### 风险分析

注意，当我们的模型没有偏差时，风险通常是正的。这意味着即使是一个最优模型也会有预测误差。直观地说，这是因为一个常量模型只能预测一个数字，而$x$可能会从总体中获取任何值。方差项捕获误差的大小。低方差意味着$x$可能取接近于$theta$的值，而高方差意味着$x$更可能取远离$theta$的值。

### 经验风险最小化

根据以上分析，我们希望设置$\theta=\mathbb e[x]$。不幸的是，计算$\mathbb e[x]$需要完整的人口知识。要了解原因，请检查$\mathbb e[x]$的表达式：

$$ \begin{aligned} \mathbb{E}[X] = \sum_{x \in \mathbb{X}} x \cdot P(X = x) \end{aligned} $$

$P（x=x）$表示$X$从总体上接受特定值的概率。然而，要计算这个概率，我们需要知道 x$的所有可能值以及它们在人群中出现的频率。换句话说，为了将模型对人口的风险降到最低，我们需要访问人口。

我们可以通过记住一个大的随机样本中的值的分布将接近人口中的值的分布来解决这个问题。如果我们的样本是真的，我们可以将样本视为种群本身。

假设我们从样本中随机抽取点，而不是人口。由于样本$\mathbf x=x 1，x 2，ldots，x n$中有$N$总点数，因此每个点$X i$都有出现的概率$\frac 1 n。现在我们可以为$\mathbb e[x]$创建近似值：

$$ \begin{aligned} \mathbb{E}[X] &\approx \frac{1}{n} \sum_{i=1}^n x_i = \text{mean}({\mathbf{x}}) \end{aligned} $$

因此，使用随机样本中捕获的信息，我们对$\theta^*$的最佳估计是$\hat \theta=\text mean（\mathbf x）$。我们说，$\hat \theta$minimized the**experimental risk**，the risk calculated using the sample as a stand in for the population.

#### 随机抽样的重要性

在上述近似中，必须注意随机抽样的重要性。如果我们的样本是非随机的，我们不能假设样本的分布与人群的分布相似。使用非随机样本估计$\theta^*$通常会导致有偏估计和更高的风险。

#### 损失最小化连接

回想一下，我们之前显示的$\Hat \Theta=\Text Mean（\MathBF X）$将数据集上的 MSE 损失最小化。现在，我们迈出了有意义的一步。如果我们的培训数据是随机样本，那么$\hat \theta=\text mean（\mathbf x）$不仅为其培训数据生成最佳模型，而且根据我们样本中的信息为总体生成最佳模型。

## 摘要[¶](#Summary)

使用本章中开发的数学工具，我们了解了模型在总体上的性能。如果模型将统计风险（htg1）降到最低，它就可以做出准确的预测。我们发现全局最优模型参数为：

$$ \begin{aligned} \theta^* = \mathbb{E}[X] \end{aligned} $$

由于我们不能很容易地计算出这一点，因此我们找到了最小化**经验风险**的模型参数。

$$ \begin{aligned} \hat \theta = \text{mean}(\mathbf x) \end{aligned} $$

如果训练数据是从人群中随机抽样的，那么$\hat \theta \约\theta ^*$。因此，一个对大量随机样本进行训练的常量模型也很可能在人群中表现良好。